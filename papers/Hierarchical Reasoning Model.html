<!DOCTYPE html>
<!-- saved from url=(0035)https://arxiv.org/html/2506.21734v3 -->
<html lang="en" data-theme="light"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>Hierarchical Reasoning Model</title>
<!--Generated on Sat Sep 27 11:40:27 2025 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="./Hierarchical Reasoning Model_files/arxiv-html-papers-20250916.css" rel="stylesheet" type="text/css">
<script src="./Hierarchical Reasoning Model_files/bootstrap.bundle.min.js.pobrane"></script>
<script src="./Hierarchical Reasoning Model_files/html2canvas.min.js.pobrane"></script>
<script src="./Hierarchical Reasoning Model_files/addons_new.js.pobrane"></script>
<script src="./Hierarchical Reasoning Model_files/feedbackOverlay.js.pobrane"></script>
<!--<base href="/html/2506.21734v3/">--><base href="."><link rel="stylesheet" href="./Hierarchical Reasoning Model_files/utz6mli.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"></head>
<body><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="./Hierarchical Reasoning Model_files/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2506.21734v3">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode" aria-label="System preference">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        <label id="light-tog" class="toggle-icon" title="Switch to dark mode" for="__palette_1" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
        <label id="dark-tog" class="toggle-icon" title="Switch to system preference" for="__palette_2" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main &gt;.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="./Hierarchical Reasoning Model_files/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="https://arxiv.org/html/2506.21734v3/#myForm" onclick="event.preventDefault(); var modal = document.getElementById(&#39;myForm&#39;); modal.style.display = &#39;block&#39;; bugReportState.setInitiateWay(&#39;Header&#39;);">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2506.21734v3">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2506.21734v3" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        <label id="light-tog" class="toggle-icon" title="Switch to dark mode" for="__palette_1" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
        <label id="dark-tog" class="toggle-icon" title="Switch to system preference" for="__palette_2" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC active" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist"><li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#abstract" title="Abstract">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        Abstract
      </span>
    </a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S1" title="In Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S2" title="In Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Hierarchical Reasoning Model</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S2.SS0.SSS0.Px1" title="In 2 Hierarchical Reasoning Model ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_title">Hierarchical convergence</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S2.SS0.SSS0.Px2" title="In 2 Hierarchical Reasoning Model ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_title">Approximate gradient</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S2.SS0.SSS0.Px3" title="In 2 Hierarchical Reasoning Model ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_title">Deep supervision</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S2.SS0.SSS0.Px4" title="In 2 Hierarchical Reasoning Model ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_title">Adaptive computational time (ACT)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S2.SS0.SSS0.Px5" title="In 2 Hierarchical Reasoning Model ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_title">Inference-time scaling</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S2.SS0.SSS0.Px6" title="In 2 Hierarchical Reasoning Model ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_title">Stability of Q-learning in ACT</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S2.SS0.SSS0.Px7" title="In 2 Hierarchical Reasoning Model ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_title">Architectural details</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S3" title="In Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S3.SS1" title="In 3 Results ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Benchmarks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S3.SS2" title="In 3 Results ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Evaluation Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S3.SS3" title="In 3 Results ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Visualization of intermediate timesteps</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S4" title="In Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Brain Correspondence</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S5" title="In Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S5.SS0.SSS0.Px1" title="In 5 Related Work ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_title">Reasoning and algorithm learning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S5.SS0.SSS0.Px2" title="In 5 Related Work ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_title">Brain-inspired reasoning architectures</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S5.SS0.SSS0.Px3" title="In 5 Related Work ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_title">Hierarchical memory</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S6" title="In Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Discussions</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S6.SS0.SSS0.Px1" title="In 6 Discussions ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_title">Turing-completeness of HRM</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S6.SS0.SSS0.Px2" title="In 6 Discussions ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_title">Reinforcement learning with chain-of-thought</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S6.SS0.SSS0.Px3" title="In 6 Discussions ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_title">Linear attention</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S7" title="In Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib" title="References">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        References
      </span>
    </a></li></ol></nav>

<div class="ltx_page_content"><div id="target-section" class="section"><a id="license-tr" href="https://info.arxiv.org/help/license/index.html#licenses-available">License: CC BY 4.0</a><div id="watermark-tr">arXiv:2506.21734v3 [cs.AI] 04 Aug 2025</div></div>
<article class="ltx_document ltx_authors_1line" lang="en">
<h1 class="ltx_title ltx_title_document">Hierarchical Reasoning Model</h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span class="ltx_text" style="font-size:80%;">Guan Wang<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">1,†</span></sup>, Jin Li<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">1</span></sup>, Yuhao Sun<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">1</span></sup>, Xing Chen<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">1</span></sup>, Changling Liu<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">1</span></sup>, 
<br class="ltx_break">Yue Wu<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">1</span></sup>, Meng Lu<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">1,†</span></sup>, Sen Song<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">2,†</span></sup>, Yasin Abbasi Yadkori<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">1,†</span></sup>
<br class="ltx_break">
<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">1</span></sup>Sapient Intelligence, Singapore
</span>
</span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract" id="abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p">Reasoning, the process of devising and executing complex goal-oriented action sequences, remains a critical challenge in AI.
Current large language models (LLMs) primarily employ Chain-of-Thought (CoT) techniques, which suffer from brittle task decomposition, extensive data requirements, and high latency. Inspired by the hierarchical and multi-timescale processing in the human brain, we propose the Hierarchical Reasoning Model (HRM), a novel recurrent architecture that attains significant computational depth while maintaining both training stability and efficiency.
HRM executes sequential reasoning tasks in a single forward pass without explicit supervision of the intermediate process, through two interdependent recurrent modules: a high-level module responsible for slow, abstract planning, and a low-level module handling rapid, detailed computations. With only 27 million parameters, HRM achieves exceptional performance on complex reasoning tasks using only 1000 training samples. The model operates without pre-training or CoT data, yet achieves nearly perfect performance on challenging tasks including complex Sudoku puzzles and optimal path finding in large mazes.
Furthermore, HRM outperforms much larger models with significantly longer context windows on the Abstraction and Reasoning Corpus (ARC), a key benchmark for measuring artificial general intelligence capabilities.
These results underscore HRM’s potential as a transformative advancement toward universal computation and general-purpose reasoning systems.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<span class="ltx_note ltx_role_footnotetext" id="footnotex1"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">footnotetext: </span>Tsinghua University <sup class="ltx_sup"><span class="ltx_text ltx_font_italic">†</span></sup> Corresponding author. Contact: <span class="ltx_text ltx_font_typewriter">research@sapient.inc</span>.
Code available at: <a class="ltx_ref ltx_href ltx_font_typewriter" href="https://github.com/sapientinc/HRM" title="">github.com/sapientinc/HRM</a></span></span></span>
<figure class="ltx_figure" id="S0.F1"><span class="ltx_inline-block"><svg class="ltx_picture ltx_centering" height="146" id="S0.F1.pic1" overflow="visible" version="1.1" viewBox="0 0 610 146" width="610"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="translate(0,146) matrix(1 0 0 -1 0 0) translate(0,73)"><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0 -66)"><foreignobject height="132" overflow="visible" style="--fo_width :15.18em;--fo_height:9.54em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 132)" width="210"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="182" id="S0.F1.pic1.g1" src="./Hierarchical Reasoning Model_files/x1.png" width="290"></span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 221 -73)"><foreignobject height="146" overflow="visible" style="--fo_width :28.11em;--fo_height:10.55em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 146)" width="389"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="202" id="S0.F1.pic1.g2" src="./Hierarchical Reasoning Model_files/x2.png" width="540"></span></span></foreignobject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button></span>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text ltx_font_bold" style="font-size:90%;">Left:<span class="ltx_text ltx_font_medium"> HRM is inspired by hierarchical processing and temporal separation in the brain. It has two recurrent networks operating at different timescales to collaboratively solve tasks. </span>Right:<span class="ltx_text ltx_font_medium"> With only about 1000 training examples, the HRM (~27M parameters) surpasses state-of-the-art CoT models on inductive benchmarks (ARC-AGI) and challenging symbolic tree-search puzzles (<span class="ltx_text ltx_font_italic">Sudoku-Extreme</span>, <span class="ltx_text ltx_font_italic">Maze-Hard</span>) where CoT models failed completely. The HRM was randomly initialized, and it solved the tasks directly from inputs without chain of thoughts.</span></span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p">Deep learning, as its name suggests, emerged from the idea of stacking more layers to achieve increased representation power and improved performance <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib2" title="">2</a></sup></cite>. However, despite the remarkable success of large language models, their core architecture is paradoxically shallow <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib3" title="">3</a></sup></cite>. This imposes a fundamental constraint on their most sought-after capability: reasoning. The fixed depth of standard Transformers places them in computational complexity classes such as <math alttext="AC^{0}" class="ltx_Math" display="inline" id="S1.p1.m1" intent=":literal"><semantics><mrow><mi>A</mi><mo lspace="0em" rspace="0em">​</mo><msup><mi>C</mi><mn>0</mn></msup></mrow><annotation encoding="application/x-tex">AC^{0}</annotation></semantics></math> or <math alttext="TC^{0}" class="ltx_Math" display="inline" id="S1.p1.m2" intent=":literal"><semantics><mrow><mi>T</mi><mo lspace="0em" rspace="0em">​</mo><msup><mi>C</mi><mn>0</mn></msup></mrow><annotation encoding="application/x-tex">TC^{0}</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib4" title="">4</a></sup></cite>, preventing them from solving problems that require polynomial time <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib6" title="">6</a></sup></cite>. LLMs are not Turing-complete and thus they cannot, at least in a purely end-to-end manner, execute complex algorithmic reasoning that is necessary for deliberate planning or symbolic manipulation tasks <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib8" title="">8</a></sup></cite>. For example, our results on the Sudoku task show that increasing Transformer model depth <span class="ltx_text ltx_font_italic">can</span> improve performance,<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Simply increasing the model width does not improve performance here.</span></span></span> but performance remains far from optimal even with very deep models (see <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S1.F2" title="In 1 Introduction ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_tag">Figure</span>˜<span class="ltx_text ltx_ref_tag">2</span></a>), which supports the conjectured limitations of the LLM scaling paradigm <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib9" title="">9</a></sup></cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p">The LLMs literature has relied largely on Chain-of-Thought (CoT) prompting for reasoning <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib10" title="">10</a></sup></cite>. CoT externalizes reasoning into token-level language by breaking down complex tasks into simpler intermediate steps, sequentially generating text using a shallow model <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib11" title="">11</a></sup></cite>. However, CoT for reasoning is a crutch, not a satisfactory solution. It relies on brittle, human-defined decompositions where a single misstep or a misorder of the steps can derail the reasoning process entirely <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib13" title="">13</a></sup></cite>. This dependency on explicit linguistic steps tethers reasoning to
patterns at the token level. As a result, CoT reasoning often requires significant amount of training data and generates a large number of tokens for complex reasoning tasks, resulting in slow response times. A more efficient approach is needed to minimize these data requirements <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib14" title="">14</a></sup></cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p">Towards this goal, we explore “latent reasoning”, where the model conducts computations within its internal hidden state space <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib16" title="">16</a></sup></cite>. This aligns with the understanding that language is a tool for human communication, not the substrate of thought itself <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib17" title="">17</a></sup></cite>; the brain sustains lengthy, coherent chains of reasoning with remarkable efficiency in a latent space, without constant translation back to language. However, the power of latent reasoning is still fundamentally constrained by a model’s <span class="ltx_text ltx_font_italic">effective computational depth</span>. Naively stacking layers is notoriously difficult due to vanishing gradients, which plague training stability and effectiveness <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib1" title="">1</a></sup>, <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib18" title="">18</a></sup></cite>. Recurrent architectures, a natural alternative for sequential tasks, often suffer from early convergence, rendering subsequent computational steps inert, and rely on the biologically implausible, computationally expensive and memory intensive Backpropagation Through Time (BPTT) for training <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib19" title="">19</a></sup></cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p">The human brain provides a compelling blueprint for achieving the effective computational depth that contemporary artificial models lack. It organizes computation hierarchically across cortical regions operating at different timescales, enabling deep, multi-stage reasoning <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib20" title="">20</a></sup>, <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib21" title="">21</a></sup>, <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib22" title="">22</a></sup></cite>. Recurrent feedback loops iteratively refine internal representations, allowing slow, higher-level areas to guide, and fast, lower-level circuits to execute—subordinate processing while preserving global coherence <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib23" title="">23</a></sup>, <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib24" title="">24</a></sup>, <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib25" title="">25</a></sup></cite>. Notably, the brain achieves such depth without incurring the prohibitive credit-assignment costs that typically hamper recurrent networks from backpropagation through time <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib19" title="">19</a></sup>, <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib26" title="">26</a></sup></cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S1.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="240" id="S1.F2.g1" src="./Hierarchical Reasoning Model_files/x3.png" width="747">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text ltx_font_bold" style="font-size:90%;">The necessity of depth for complex reasoning.<span class="ltx_text ltx_font_medium"> </span>Left:<span class="ltx_text ltx_font_medium"> On <span class="ltx_text ltx_font_italic">Sudoku-Extreme Full</span>, which require extensive tree-search and backtracking, increasing a Transformer’s width yields no performance gain, while increasing depth is critical. </span>Right:<span class="ltx_text ltx_font_medium"> Standard architectures saturates, failing to benefit from increased depth. HRM overcomes this fundamental limitation, effectively using its computational depth to achieve near-perfect accuracy.</span></span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S1.p5">
<p class="ltx_p">Inspired by this hierarchical and multi-timescale biological architecture, we propose the Hierarchical Reasoning Model (HRM). HRM is designed to significantly increase the effective computational depth. It features two coupled recurrent modules: a high-level (H) module for abstract, deliberate reasoning, and a low-level (L) module for fast, detailed computations. This structure avoids the rapid convergence of standard recurrent models through a process we term “hierarchical convergence.” The slow-updating H-module advances only after the fast-updating L-module has completed multiple computational steps and reached a local equilibrium, at which point the L-module is reset to begin a new computational phase.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S1.p6">
<p class="ltx_p">Furthermore, we propose a one-step gradient approximation for training HRM, which offers improved efficiency and eliminates the requirement for BPTT. This design maintains a constant memory footprint (<math alttext="O(1)" class="ltx_Math" display="inline" id="S1.p6.m1" intent=":literal"><semantics><mrow><mi>O</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">O(1)</annotation></semantics></math> compared to BPTT’s <math alttext="O(T)" class="ltx_Math" display="inline" id="S1.p6.m2" intent=":literal"><semantics><mrow><mi>O</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>T</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">O(T)</annotation></semantics></math> for <math alttext="T" class="ltx_Math" display="inline" id="S1.p6.m3" intent=":literal"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math> timesteps) throughout the backpropagation process, making it scalable and more biologically plausible.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S1.p7">
<p class="ltx_p">Leveraging its enhanced effective depth, HRM excels at tasks that demand extensive search and backtracking. <span class="ltx_text ltx_font_bold">Using only 1,000 input-output examples, without pre-training or CoT supervision</span>, HRM learns to solve problems that are intractable for even the most advanced LLMs. For example, it achieves near-perfect accuracy in complex Sudoku puzzles (<span class="ltx_text ltx_font_italic">Sudoku-Extreme Full</span>) and optimal pathfinding in 30x30 mazes, where state-of-the-art CoT methods completely fail (0% accuracy). In the Abstraction and Reasoning Corpus (ARC) AGI Challenge <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib27" title="">27</a>, <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib28" title="">28</a>, <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib29" title="">29</a></sup></cite> - a benchmark of inductive reasoning - HRM, trained from scratch with only the official dataset (~1000 examples), with only 27M parameters and a 30x30 grid context (900 tokens), achieves a performance of <span class="ltx_text ltx_font_bold">40.3%</span>, which substantially surpasses leading CoT-based models like o3-mini-high (34.5%) and Claude 3.7 8K context (21.2%), despite their considerably larger parameter sizes and context lengths, as shown in <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S0.F1" title="In Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_tag">Figure</span>˜<span class="ltx_text ltx_ref_tag">1</span></a>. This represents a promising direction toward the development of next-generation AI reasoning systems with universal computational capabilities.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Hierarchical Reasoning Model</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p">We present the HRM, inspired by three fundamental principles of neural computation observed in the brain:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.p2">
<ul class="ltx_itemize" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Hierarchical processing:</span> The brain processes information across a hierarchy of cortical areas. Higher-level areas integrate information over longer timescales and form abstract representations, while lower-level areas handle more immediate, detailed sensory and motor processing <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib20" title="">20</a></sup>, <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib22" title="">22</a></sup>, <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib21" title="">21</a></sup></cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Temporal Separation:</span> These hierarchical levels in the brain operate at distinct intrinsic timescales, reflected in neural rhythms (e.g., slow theta waves, 4–8 Hz and fast gamma waves, 30–100 Hz) <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib30" title="">30</a></sup>, <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib31" title="">31</a></sup></cite>. This separation allows for stable, high-level guidance of rapid, low-level computations <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib32" title="">32</a></sup>, <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib33" title="">33</a></sup></cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S2.I1.i3.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Recurrent Connectivity:</span> The brain features extensive recurrent connections. These feedback loops enable iterative refinement, yielding more accurate and context-sensitive representations at the cost of additional processing time. Additionally, the brain largely avoids the problematic deep credit assignment problem associated with BPTT <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib19" title="">19</a></sup></cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S2.p3">
<p class="ltx_p">The HRM model consists of four learnable components: an input network <math alttext="f_{I}(\cdot;\theta_{I})" class="ltx_Math" display="inline" id="S2.p3.m1" intent=":literal"><semantics><mrow><msub><mi>f</mi><mi>I</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mo lspace="0em" rspace="0em">⋅</mo><mo>;</mo><msub><mi>θ</mi><mi>I</mi></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">f_{I}(\cdot;\theta_{I})</annotation></semantics></math>, a low-level recurrent module <math alttext="f_{L}(\cdot;\theta_{L})" class="ltx_Math" display="inline" id="S2.p3.m2" intent=":literal"><semantics><mrow><msub><mi>f</mi><mi>L</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mo lspace="0em" rspace="0em">⋅</mo><mo>;</mo><msub><mi>θ</mi><mi>L</mi></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">f_{L}(\cdot;\theta_{L})</annotation></semantics></math>, a high-level recurrent module <math alttext="f_{H}(\cdot;\theta_{H})" class="ltx_Math" display="inline" id="S2.p3.m3" intent=":literal"><semantics><mrow><msub><mi>f</mi><mi>H</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mo lspace="0em" rspace="0em">⋅</mo><mo>;</mo><msub><mi>θ</mi><mi>H</mi></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">f_{H}(\cdot;\theta_{H})</annotation></semantics></math>, and an output network <math alttext="f_{O}(\cdot;\theta_{O})" class="ltx_Math" display="inline" id="S2.p3.m4" intent=":literal"><semantics><mrow><msub><mi>f</mi><mi>O</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mo lspace="0em" rspace="0em">⋅</mo><mo>;</mo><msub><mi>θ</mi><mi>O</mi></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">f_{O}(\cdot;\theta_{O})</annotation></semantics></math>. The model’s dynamics unfold over <math alttext="N" class="ltx_Math" display="inline" id="S2.p3.m5" intent=":literal"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math> high-level cycles of <math alttext="T" class="ltx_Math" display="inline" id="S2.p3.m6" intent=":literal"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math> low-level timesteps each<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>While inspired by temporal separation in the brain, our model’s “high-level” and “low-level” modules are conceptual abstractions and do not map directly to specific neural oscillation frequencies.</span></span></span>. We index the total timesteps of one forward pass by <math alttext="i=1,\dots,N\times T" class="ltx_Math" display="inline" id="S2.p3.m7" intent=":literal"><semantics><mrow><mi>i</mi><mo>=</mo><mrow><mn>1</mn><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><mrow><mi>N</mi><mo lspace="0.222em" rspace="0.222em">×</mo><mi>T</mi></mrow></mrow></mrow><annotation encoding="application/x-tex">i=1,\dots,N\times T</annotation></semantics></math>. The modules <math alttext="f_{L}" class="ltx_Math" display="inline" id="S2.p3.m8" intent=":literal"><semantics><msub><mi>f</mi><mi>L</mi></msub><annotation encoding="application/x-tex">f_{L}</annotation></semantics></math> and <math alttext="f_{H}" class="ltx_Math" display="inline" id="S2.p3.m9" intent=":literal"><semantics><msub><mi>f</mi><mi>H</mi></msub><annotation encoding="application/x-tex">f_{H}</annotation></semantics></math> each keep a hidden state—<math alttext="z_{L}^{i}" class="ltx_Math" display="inline" id="S2.p3.m10" intent=":literal"><semantics><msubsup><mi>z</mi><mi>L</mi><mi>i</mi></msubsup><annotation encoding="application/x-tex">z_{L}^{i}</annotation></semantics></math> for <math alttext="f_{L}" class="ltx_Math" display="inline" id="S2.p3.m11" intent=":literal"><semantics><msub><mi>f</mi><mi>L</mi></msub><annotation encoding="application/x-tex">f_{L}</annotation></semantics></math> and <math alttext="z_{H}^{i}" class="ltx_Math" display="inline" id="S2.p3.m12" intent=":literal"><semantics><msubsup><mi>z</mi><mi>H</mi><mi>i</mi></msubsup><annotation encoding="application/x-tex">z_{H}^{i}</annotation></semantics></math> for <math alttext="f_{H}" class="ltx_Math" display="inline" id="S2.p3.m13" intent=":literal"><semantics><msub><mi>f</mi><mi>H</mi></msub><annotation encoding="application/x-tex">f_{H}</annotation></semantics></math>—which are initialized with the vectors <math alttext="z_{L}^{0}" class="ltx_Math" display="inline" id="S2.p3.m14" intent=":literal"><semantics><msubsup><mi>z</mi><mi>L</mi><mn>0</mn></msubsup><annotation encoding="application/x-tex">z_{L}^{0}</annotation></semantics></math> and <math alttext="z_{H}^{0}" class="ltx_Math" display="inline" id="S2.p3.m15" intent=":literal"><semantics><msubsup><mi>z</mi><mi>H</mi><mn>0</mn></msubsup><annotation encoding="application/x-tex">z_{H}^{0}</annotation></semantics></math>, respectively.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.p4">
<p class="ltx_p">The HRM maps an input vector <math alttext="x" class="ltx_Math" display="inline" id="S2.p4.m1" intent=":literal"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math> to an output prediction vector <math alttext="\hat{y}" class="ltx_Math" display="inline" id="S2.p4.m2" intent=":literal"><semantics><mover accent="true"><mi>y</mi><mo>^</mo></mover><annotation encoding="application/x-tex">\hat{y}</annotation></semantics></math> as follows. First, the input <math alttext="x" class="ltx_Math" display="inline" id="S2.p4.m3" intent=":literal"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math> is projected into a working representation <math alttext="\tilde{x}" class="ltx_Math" display="inline" id="S2.p4.m4" intent=":literal"><semantics><mover accent="true"><mi>x</mi><mo>~</mo></mover><annotation encoding="application/x-tex">\tilde{x}</annotation></semantics></math> by the input network:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S2.Ex1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\tilde{x}=f_{I}(x;\theta_{I})\;." class="ltx_Math" display="block" id="S2.Ex1.m1" intent=":literal"><semantics><mrow><mrow><mover accent="true"><mi>x</mi><mo>~</mo></mover><mo>=</mo><mrow><msub><mi>f</mi><mi>I</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>;</mo><msub><mi>θ</mi><mi>I</mi></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>.</mo></mrow><annotation encoding="application/x-tex">\tilde{x}=f_{I}(x;\theta_{I})\;.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">At each timestep <math alttext="i" class="ltx_Math" display="inline" id="S2.p4.m5" intent=":literal"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>, the L-module updates its state conditioned on its own previous state, the H-module’s current state (which remains fixed throughout the cycle), and the input representation. The H-module only updates once per cycle (i.e., every <math alttext="T" class="ltx_Math" display="inline" id="S2.p4.m6" intent=":literal"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math> timesteps) using the L-module’s final state at the end of that cycle:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A0.EGx1">
<tbody id="S2.Ex2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle z_{L}^{i}" class="ltx_Math" display="inline" id="S2.Ex2.m1" intent=":literal"><semantics><msubsup><mi>z</mi><mi>L</mi><mi>i</mi></msubsup><annotation encoding="application/x-tex">\displaystyle z_{L}^{i}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=f_{L}\left(z_{L}^{i-1},z_{H}^{i-1},\tilde{x};\theta_{L}\right)\,," class="ltx_Math" display="inline" id="S2.Ex2.m2" intent=":literal"><semantics><mrow><mrow><mi></mi><mo>=</mo><mrow><msub><mi>f</mi><mi>L</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo>(</mo><msubsup><mi>z</mi><mi>L</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msubsup><mo>,</mo><msubsup><mi>z</mi><mi>H</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msubsup><mo>,</mo><mover accent="true"><mi>x</mi><mo>~</mo></mover><mo>;</mo><msub><mi>θ</mi><mi>L</mi></msub><mo rspace="0.170em">)</mo></mrow></mrow></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\displaystyle=f_{L}\left(z_{L}^{i-1},z_{H}^{i-1},\tilde{x};\theta_{L}\right)\,,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.Ex3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle z_{H}^{i}" class="ltx_Math" display="inline" id="S2.Ex3.m1" intent=":literal"><semantics><msubsup><mi>z</mi><mi>H</mi><mi>i</mi></msubsup><annotation encoding="application/x-tex">\displaystyle z_{H}^{i}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\begin{cases}f_{H}\left(z_{H}^{i-1},z_{L}^{i-1};\theta_{H}\right)&amp;\text{if }i\equiv 0\ (\mathrm{mod}\ T)\,,\\
z_{H}^{i-1}&amp;\text{otherwise }\;.\end{cases}" class="ltx_Math" display="inline" id="S2.Ex3.m2" intent=":literal"><semantics><mrow><mi></mi><mo>=</mo><mrow><mo>{</mo><mtable columnspacing="5pt" rowspacing="0pt"><mtr><mtd class="ltx_align_left" columnalign="left"><mrow><msub><mi>f</mi><mi>H</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo>(</mo><msubsup><mi>z</mi><mi>H</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msubsup><mo>,</mo><msubsup><mi>z</mi><mi>L</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msubsup><mo>;</mo><msub><mi>θ</mi><mi>H</mi></msub><mo>)</mo></mrow></mrow></mtd><mtd class="ltx_align_left" columnalign="left"><mrow><mrow><mrow><mtext>if&nbsp;</mtext><mo lspace="0em" rspace="0em">​</mo><mi>i</mi></mrow><mo>≡</mo><mrow><mn>0</mn><mo lspace="0.500em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>mod</mi><mo lspace="0.500em" rspace="0em">​</mo><mi>T</mi></mrow><mo rspace="0.170em" stretchy="false">)</mo></mrow></mrow></mrow><mo>,</mo></mrow></mtd></mtr><mtr><mtd class="ltx_align_left" columnalign="left"><msubsup><mi>z</mi><mi>H</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msubsup></mtd><mtd class="ltx_align_left" columnalign="left"><mrow><mtext>otherwise&nbsp;</mtext><mo>.</mo></mrow></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">\displaystyle=\begin{cases}f_{H}\left(z_{H}^{i-1},z_{L}^{i-1};\theta_{H}\right)&amp;\text{if }i\equiv 0\ (\mathrm{mod}\ T)\,,\\
z_{H}^{i-1}&amp;\text{otherwise }\;.\end{cases}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S2.p5">
<p class="ltx_p">Finally, after <math alttext="N" class="ltx_Math" display="inline" id="S2.p5.m1" intent=":literal"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math> full cycles, a prediction <math alttext="\hat{y}" class="ltx_Math" display="inline" id="S2.p5.m2" intent=":literal"><semantics><mover accent="true"><mi>y</mi><mo>^</mo></mover><annotation encoding="application/x-tex">\hat{y}</annotation></semantics></math> is extracted from the hidden state of the H-module:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.p6">
<table class="ltx_equation ltx_eqn_table" id="S2.Ex4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\hat{y}=f_{O}(z_{H}^{NT};\theta_{O})\;." class="ltx_Math" display="block" id="S2.Ex4.m1" intent=":literal"><semantics><mrow><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>=</mo><mrow><msub><mi>f</mi><mi>O</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msubsup><mi>z</mi><mi>H</mi><mrow><mi>N</mi><mo lspace="0em" rspace="0em">​</mo><mi>T</mi></mrow></msubsup><mo>;</mo><msub><mi>θ</mi><mi>O</mi></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>.</mo></mrow><annotation encoding="application/x-tex">\hat{y}=f_{O}(z_{H}^{NT};\theta_{O})\;.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S2.p7">
<p class="ltx_p">This entire <math alttext="NT" class="ltx_Math" display="inline" id="S2.p7.m1" intent=":literal"><semantics><mrow><mi>N</mi><mo lspace="0em" rspace="0em">​</mo><mi>T</mi></mrow><annotation encoding="application/x-tex">NT</annotation></semantics></math>-timestep process represents a single forward pass of the HRM. A halting mechanism (detailed later in this section) determines whether the model should terminate, in which case <math alttext="\hat{y}" class="ltx_Math" display="inline" id="S2.p7.m2" intent=":literal"><semantics><mover accent="true"><mi>y</mi><mo>^</mo></mover><annotation encoding="application/x-tex">\hat{y}</annotation></semantics></math> will be used as the final prediction, or continue with an additional forward pass.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Hierarchical convergence</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S2.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="363" id="S2.F3.g1" src="./Hierarchical Reasoning Model_files/x4.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" style="font-size:90%;">Comparison of forward residuals and PCA trajectories. HRM shows hierarchical convergence: the H-module steadily converges, while the L-module repeatedly converges within cycles before being reset by H, resulting in residual spikes. The recurrent neural network exhibits rapid convergence with residuals quickly approaching zero. In contrast, the deep neural network experiences vanishing gradients, with significant residuals primarily in the initial (input) and final layers.</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p">Although convergence is crucial for recurrent networks, standard RNNs are fundamentally limited by their tendency to converge too early. As the hidden state settles toward a fixed point, update magnitudes shrink, effectively stalling subsequent computation and capping the network’s effective depth. To preserve computational power, we actually want convergence to proceed very slowly–but engineering that gradual approach is difficult, since pushing convergence too far edges the system toward instability.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px1.p2">
<p class="ltx_p">HRM is explicitly designed to counteract this premature convergence through a process we term <span class="ltx_text ltx_font_italic">hierarchical convergence</span>. During each cycle, the L-module (an RNN) exhibits stable convergence to a <span class="ltx_text ltx_font_italic">local equilibrium</span>. This equilibrium, however, depends on the high-level state <math alttext="z_{H}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.p2.m1" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math> supplied during that cycle. After completing the <math alttext="T" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.p2.m2" intent=":literal"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math> steps, the H-module incorporates the sub-computation’s outcome (the final state <math alttext="z_{L}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.p2.m3" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">z_{L}</annotation></semantics></math>) and performs its own update. This <math alttext="z_{H}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.p2.m4" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math> update establishes a fresh context for the L-module, essentially “restarting” its computational path and initiating a new convergence phase toward a different local equilibrium.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px1.p3">
<p class="ltx_p">This process allows the HRM to perform a sequence of distinct, stable, nested computations, where the H-module directs the overall problem-solving strategy and the L-module executes the intensive search or refinement required for each step. Although a standard RNN may approach convergence within <math alttext="T" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.p3.m1" intent=":literal"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math> iterations, the hierarchical convergence benefits from an enhanced effective depth of <math alttext="NT" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.p3.m2" intent=":literal"><semantics><mrow><mi>N</mi><mo lspace="0em" rspace="0em">​</mo><mi>T</mi></mrow><annotation encoding="application/x-tex">NT</annotation></semantics></math> steps. As empirically shown in <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S2.F3" title="In Hierarchical convergence ‣ 2 Hierarchical Reasoning Model ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_tag">Figure</span>˜<span class="ltx_text ltx_ref_tag">3</span></a>, this mechanism allows HRM both to maintain high computational activity (forward residual) over many steps (in contrast to a standard RNN, whose activity rapidly decays) and to enjoy stable convergence. This translates into better performance at any computation depth, as illustrated in <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S1.F2" title="In 1 Introduction ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_tag">Figure</span>˜<span class="ltx_text ltx_ref_tag">2</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Approximate gradient</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px2.p1">
<p class="ltx_p">Recurrent models typically use BPTT to compute gradients. However, BPTT requires storing the hidden states from the forward pass and then combining them with gradients during the backward pass, which demands <math alttext="O(T)" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p1.m1" intent=":literal"><semantics><mrow><mi>O</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>T</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">O(T)</annotation></semantics></math> memory for T timesteps. This heavy memory burden forces smaller batch sizes and leads to poor GPU utilization, especially for large-scale networks. Additionally, because retaining the full history trace through time is biologically implausible, it is unlikely that the brain implements BPTT <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib19" title="">19</a></sup></cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px2.p2">
<p class="ltx_p">Fortunately, if a recurrent neural network converges to a fixed point, we can avoid unrolling its state sequence by applying backpropagation in a single step at that equilibrium point. Moreover, such a mechanism could plausibly be implemented in the brain using only local learning rules <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib34" title="">34</a>, <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib35" title="">35</a></sup></cite>. Based on this finding, we propose a one-step approximation of the HRM gradient–using the gradient of the last state of each module and treating other states as constant. The gradient path is, therefore,</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<blockquote class="ltx_quote">
<p class="ltx_p"><span class="ltx_text" style="font-size:90%;">Output head → final state of the H-module → final state of the L-module → input embedding</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</blockquote>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px2.p3">
<p class="ltx_p">The above method needs <math alttext="O(1)" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p3.m1" intent=":literal"><semantics><mrow><mi>O</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">O(1)</annotation></semantics></math> memory, does not require unrolling through time, and can be easily implemented with an autograd framework such as PyTorch, as shown in <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S2.F4" title="In Approximate gradient ‣ 2 Hierarchical Reasoning Model ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_tag">Figure</span>˜<span class="ltx_text ltx_ref_tag">4</span></a>. Given that each module only needs to back-propagate errors through its most recent local synaptic activity, this approach aligns well with the perspective that cortical credit assignment relies on short-range, temporally local mechanisms rather than on a global replay of activity patterns.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure ltx_align_floatright" id="S2.F4">
<div class="ltx_block ltx_minipage ltx_align_center ltx_align_top" style="width:433.6pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="317" id="S2.F4.g1" src="./Hierarchical Reasoning Model_files/x5.png" width="829">
<div class="ltx_listing ltx_lst_language_python ltx_lstlisting ltx_listing" style="--ltx-bg-color:#FFFFFF;">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,ZGVmIGhybSh6LCB4LCBOPTIsIFQ9Mik6CiAgICB4ID0gaW5wdXRfZW1iZWRkaW5nKHgpCiAgICB6SCwgekwgPSB6CgogICAgd2l0aCB0b3JjaC5ub19ncmFkKCk6CiAgICAgICAgZm9yIF9pIGluIHJhbmdlKE4gKiBUIC0gMSk6CiAgICAgICAgICAgIHpMID0gTF9uZXQoekwsIHpILCB4KQogICAgICAgICAgICBpZiAoX2kgKyAxKSAlIFQgPT0gMDoKICAgICAgICAgICAgICAgIHpIID0gSF9uZXQoekgsIHpMKQoKICAgICMgMS1zdGVwIGdyYWQKICAgIHpMID0gTF9uZXQoekwsIHpILCB4KQogICAgekggPSBIX25ldCh6SCwgekwpCiAgICByZXR1cm4gKHpILCB6TCksIG91dHB1dF9oZWFkKHpIKQoKIyBEZWVwIFN1cGVydmlzaW9uCmZvciB4LCB5X3RydWUgaW4gdHJhaW5fZGF0YWxvYWRlcjoKICAgIHogPSB6X2luaXQKICAgIGZvciBzdGVwIGluIHJhbmdlKE5fc3VwZXJ2aXNpb24pOgogICAgICAgIHosIHlfaGF0ID0gaHJtKHosIHgpCgogICAgICAgIGxvc3MgPSBzb2Z0bWF4X2Nyb3NzX2VudHJvcHkoeV9oYXQsIHlfdHJ1ZSkKICAgICAgICB6ID0gei5kZXRhY2goKQoKICAgICAgICBsb3NzLmJhY2t3YXJkKCkKICAgICAgICBvcHQuc3RlcCgpCiAgICAgICAgb3B0Lnplcm9fZ3JhZCgp">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx1">
<span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">def</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">hrm</span>(<span class="ltx_text ltx_lst_identifier">z</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">x</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">N</span>=2,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">T</span>=2):
</div>
<div class="ltx_listingline" id="lstnumberx2">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">x</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">input_embedding</span>(<span class="ltx_text ltx_lst_identifier">x</span>)
</div>
<div class="ltx_listingline" id="lstnumberx3">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">zH</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">zL</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>
</div>
<div class="ltx_listingline" id="lstnumberx4">
</div>
<div class="ltx_listingline" id="lstnumberx5">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">with</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">torch</span>.<span class="ltx_text ltx_lst_identifier">no_grad</span>():
</div>
<div class="ltx_listingline" id="lstnumberx6">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">for</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">_i</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">in</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword ltx_lst_keywords2" style="--ltx-fg-color:#0000FF;">range</span>(<span class="ltx_text ltx_lst_identifier">N</span><span class="ltx_text ltx_lst_space"> </span>*<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">T</span><span class="ltx_text ltx_lst_space"> </span>-<span class="ltx_text ltx_lst_space"> </span>1):
</div>
<div class="ltx_listingline" id="lstnumberx7">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">zL</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">L_net</span>(<span class="ltx_text ltx_lst_identifier">zL</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">zH</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">x</span>)
</div>
<div class="ltx_listingline" id="lstnumberx8">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">if</span><span class="ltx_text ltx_lst_space"> </span>(<span class="ltx_text ltx_lst_identifier">_i</span><span class="ltx_text ltx_lst_space"> </span>+<span class="ltx_text ltx_lst_space"> </span>1)<span class="ltx_text ltx_lst_space"> </span>%<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">T</span><span class="ltx_text ltx_lst_space"> </span>==<span class="ltx_text ltx_lst_space"> </span>0:
</div>
<div class="ltx_listingline" id="lstnumberx9">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">zH</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">H_net</span>(<span class="ltx_text ltx_lst_identifier">zH</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">zL</span>)
</div>
<div class="ltx_listingline" id="lstnumberx10">
</div>
<div class="ltx_listingline" id="lstnumberx11">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_comment" style="--ltx-fg-color:#808080;">#<span class="ltx_text ltx_lst_space"> </span>1-step<span class="ltx_text ltx_lst_space"> </span>grad</span>
</div>
<div class="ltx_listingline" id="lstnumberx12">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">zL</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">L_net</span>(<span class="ltx_text ltx_lst_identifier">zL</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">zH</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">x</span>)
</div>
<div class="ltx_listingline" id="lstnumberx13">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">zH</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">H_net</span>(<span class="ltx_text ltx_lst_identifier">zH</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">zL</span>)
</div>
<div class="ltx_listingline" id="lstnumberx14">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">return</span><span class="ltx_text ltx_lst_space"> </span>(<span class="ltx_text ltx_lst_identifier">zH</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">zL</span>),<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">output_head</span>(<span class="ltx_text ltx_lst_identifier">zH</span>)
</div>
<div class="ltx_listingline" id="lstnumberx15">
</div>
<div class="ltx_listingline" id="lstnumberx16">
<span class="ltx_text ltx_lst_comment" style="--ltx-fg-color:#808080;">#<span class="ltx_text ltx_lst_space"> </span>Deep<span class="ltx_text ltx_lst_space"> </span>Supervision</span>
</div>
<div class="ltx_listingline" id="lstnumberx17">
<span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">for</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">x</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y_true</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">in</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">train_dataloader</span>:
</div>
<div class="ltx_listingline" id="lstnumberx18">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z_init</span>
</div>
<div class="ltx_listingline" id="lstnumberx19">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">for</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">step</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">in</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword ltx_lst_keywords2" style="--ltx-fg-color:#0000FF;">range</span>(<span class="ltx_text ltx_lst_identifier">N_supervision</span>):
</div>
<div class="ltx_listingline" id="lstnumberx20">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y_hat</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">hrm</span>(<span class="ltx_text ltx_lst_identifier">z</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">x</span>)
</div>
<div class="ltx_listingline" id="lstnumberx21">
</div>
<div class="ltx_listingline" id="lstnumberx22">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">loss</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">softmax_cross_entropy</span>(<span class="ltx_text ltx_lst_identifier">y_hat</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y_true</span>)
</div>
<div class="ltx_listingline" id="lstnumberx23">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>.<span class="ltx_text ltx_lst_identifier">detach</span>()
</div>
<div class="ltx_listingline" id="lstnumberx24">
</div>
<div class="ltx_listingline" id="lstnumberx25">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">loss</span>.<span class="ltx_text ltx_lst_identifier">backward</span>()
</div>
<div class="ltx_listingline" id="lstnumberx26">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">opt</span>.<span class="ltx_text ltx_lst_identifier">step</span>()
</div>
<div class="ltx_listingline" id="lstnumberx27">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">opt</span>.<span class="ltx_text ltx_lst_identifier">zero_grad</span>()
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text ltx_font_bold" style="font-size:90%;">Top:<span class="ltx_text ltx_font_medium"> Diagram of HRM with approximate gradient. </span>Bottom:<span class="ltx_text ltx_font_medium"> Pseudocode of HRM with deep supervision training in PyTorch.</span></span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px2.p4">
<p class="ltx_p">The one-step gradient approximation is theoretically grounded in the mathematics of Deep Equilibrium Models (DEQ) <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib36" title="">36</a></sup></cite> which employs the Implicit Function Theorem (IFT) to bypass BPTT, as detailed next. Consider an idealized HRM behavior where, during high-level cycle <math alttext="k" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p4.m1" intent=":literal"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>, the L-module repeatedly updates until its state <math alttext="z_{L}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p4.m2" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">z_{L}</annotation></semantics></math> converges to a local fixed point <math alttext="z_{L}^{\star}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p4.m3" intent=":literal"><semantics><msubsup><mi>z</mi><mi>L</mi><mo>⋆</mo></msubsup><annotation encoding="application/x-tex">z_{L}^{\star}</annotation></semantics></math>. This fixed point, given the current high-level state <math alttext="z_{H}^{k-1}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p4.m4" intent=":literal"><semantics><msubsup><mi>z</mi><mi>H</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msubsup><annotation encoding="application/x-tex">z_{H}^{k-1}</annotation></semantics></math>, can be expressed as</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S2.Ex5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="z_{L}^{\star}=f_{L}(z_{L}^{\star},z_{H}^{k-1},\tilde{x};\theta_{L})\;." class="ltx_Math" display="block" id="S2.Ex5.m1" intent=":literal"><semantics><mrow><mrow><msubsup><mi>z</mi><mi>L</mi><mo>⋆</mo></msubsup><mo>=</mo><mrow><msub><mi>f</mi><mi>L</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msubsup><mi>z</mi><mi>L</mi><mo>⋆</mo></msubsup><mo>,</mo><msubsup><mi>z</mi><mi>H</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msubsup><mo>,</mo><mover accent="true"><mi>x</mi><mo>~</mo></mover><mo>;</mo><msub><mi>θ</mi><mi>L</mi></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>.</mo></mrow><annotation encoding="application/x-tex">z_{L}^{\star}=f_{L}(z_{L}^{\star},z_{H}^{k-1},\tilde{x};\theta_{L})\;.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">The H-module then performs a single update using this converged L-state:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S2.Ex6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="z_{H}^{k}=f_{H}(z_{H}^{k-1},z_{L}^{\star};\theta_{H})\;." class="ltx_Math" display="block" id="S2.Ex6.m1" intent=":literal"><semantics><mrow><mrow><msubsup><mi>z</mi><mi>H</mi><mi>k</mi></msubsup><mo>=</mo><mrow><msub><mi>f</mi><mi>H</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msubsup><mi>z</mi><mi>H</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msubsup><mo>,</mo><msubsup><mi>z</mi><mi>L</mi><mo>⋆</mo></msubsup><mo>;</mo><msub><mi>θ</mi><mi>H</mi></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>.</mo></mrow><annotation encoding="application/x-tex">z_{H}^{k}=f_{H}(z_{H}^{k-1},z_{L}^{\star};\theta_{H})\;.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">With a proper mapping <math alttext="\mathcal{F}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p4.m5" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ℱ</mi><annotation encoding="application/x-tex">\mathcal{F}</annotation></semantics></math>, the updates to the high-level state can be written in a more compact form as <math alttext="z_{H}^{k}=\mathcal{F}(z_{H}^{k-1};\tilde{x},\theta)" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p4.m6" intent=":literal"><semantics><mrow><msubsup><mi>z</mi><mi>H</mi><mi>k</mi></msubsup><mo>=</mo><mrow><mi class="ltx_font_mathcaligraphic">ℱ</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msubsup><mi>z</mi><mi>H</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msubsup><mo>;</mo><mover accent="true"><mi>x</mi><mo>~</mo></mover><mo>,</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">z_{H}^{k}=\mathcal{F}(z_{H}^{k-1};\tilde{x},\theta)</annotation></semantics></math>, where <math alttext="\theta=(\theta_{I},\theta_{L})" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p4.m7" intent=":literal"><semantics><mrow><mi>θ</mi><mo>=</mo><mrow><mo stretchy="false">(</mo><msub><mi>θ</mi><mi>I</mi></msub><mo>,</mo><msub><mi>θ</mi><mi>L</mi></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\theta=(\theta_{I},\theta_{L})</annotation></semantics></math>, and the fixed-point can be written as <math alttext="z_{H}^{\star}=\mathcal{F}(z_{H}^{\star};\tilde{x},\theta)" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p4.m8" intent=":literal"><semantics><mrow><msubsup><mi>z</mi><mi>H</mi><mo>⋆</mo></msubsup><mo>=</mo><mrow><mi class="ltx_font_mathcaligraphic">ℱ</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msubsup><mi>z</mi><mi>H</mi><mo>⋆</mo></msubsup><mo>;</mo><mover accent="true"><mi>x</mi><mo>~</mo></mover><mo>,</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">z_{H}^{\star}=\mathcal{F}(z_{H}^{\star};\tilde{x},\theta)</annotation></semantics></math>. Let <math alttext="J_{\mathcal{F}}=\frac{\partial\mathcal{F}}{\partial z_{H}}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p4.m9" intent=":literal"><semantics><mrow><msub><mi>J</mi><mi class="ltx_font_mathcaligraphic">ℱ</mi></msub><mo>=</mo><mfrac><mrow><mo rspace="0em">∂</mo><mi class="ltx_font_mathcaligraphic">ℱ</mi></mrow><mrow><mo rspace="0em">∂</mo><msub><mi>z</mi><mi>H</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">J_{\mathcal{F}}=\frac{\partial\mathcal{F}}{\partial z_{H}}</annotation></semantics></math> be the Jacobian of <math alttext="\mathcal{F}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p4.m10" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ℱ</mi><annotation encoding="application/x-tex">\mathcal{F}</annotation></semantics></math>, and assume that the matrix <math alttext="I-J_{\mathcal{F}}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p4.m11" intent=":literal"><semantics><mrow><mi>I</mi><mo>−</mo><msub><mi>J</mi><mi class="ltx_font_mathcaligraphic">ℱ</mi></msub></mrow><annotation encoding="application/x-tex">I-J_{\mathcal{F}}</annotation></semantics></math> is invertible at <math alttext="z_{H}^{\star}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p4.m12" intent=":literal"><semantics><msubsup><mi>z</mi><mi>H</mi><mo>⋆</mo></msubsup><annotation encoding="application/x-tex">z_{H}^{\star}</annotation></semantics></math> and that the mapping <math alttext="\mathcal{F}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p4.m13" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ℱ</mi><annotation encoding="application/x-tex">\mathcal{F}</annotation></semantics></math> is continuously differentiable. The Implicit Function Theorem then allows us to calculate the exact gradient of fixed point <math alttext="z_{H}^{\star}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p4.m14" intent=":literal"><semantics><msubsup><mi>z</mi><mi>H</mi><mo>⋆</mo></msubsup><annotation encoding="application/x-tex">z_{H}^{\star}</annotation></semantics></math> with respect to the parameters <math alttext="\theta" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p4.m15" intent=":literal"><semantics><mi>θ</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math> without explicit backpropagation:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\frac{\partial z_{H}^{\star}}{\partial\theta}=\left(I-J_{\mathcal{F}}\big|_{z_{H}^{\star}}\right)^{-1}\frac{\partial\mathcal{F}}{\partial\theta}\bigg|_{z_{H}^{\star}}\;." class="ltx_Math" display="block" id="S2.E1.m1" intent=":literal"><semantics><mrow><mrow><mfrac><mrow><mo rspace="0em">∂</mo><msubsup><mi>z</mi><mi>H</mi><mo>⋆</mo></msubsup></mrow><mrow><mo rspace="0em">∂</mo><mi>θ</mi></mrow></mfrac><mo>=</mo><msub><mrow><mrow><msup><mrow><mo>(</mo><mrow><mi>I</mi><mo>−</mo><msub><mrow><msub><mi>J</mi><mi class="ltx_font_mathcaligraphic">ℱ</mi></msub><mo maxsize="1.200em" minsize="1.200em" stretchy="true">|</mo></mrow><msubsup><mi>z</mi><mi>H</mi><mo>⋆</mo></msubsup></msub></mrow><mo>)</mo></mrow><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo lspace="0em" rspace="0em">​</mo><mfrac><mrow><mo rspace="0em">∂</mo><mi class="ltx_font_mathcaligraphic">ℱ</mi></mrow><mrow><mo rspace="0em">∂</mo><mi>θ</mi></mrow></mfrac></mrow><mo maxsize="2.100em" minsize="2.100em" stretchy="true">|</mo></mrow><msubsup><mi>z</mi><mi>H</mi><mo>⋆</mo></msubsup></msub></mrow><mo lspace="0em">.</mo></mrow><annotation encoding="application/x-tex">\frac{\partial z_{H}^{\star}}{\partial\theta}=\left(I-J_{\mathcal{F}}\big|_{z_{H}^{\star}}\right)^{-1}\frac{\partial\mathcal{F}}{\partial\theta}\bigg|_{z_{H}^{\star}}\;.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px2.p5">
<p class="ltx_p">Calculating the above gradient requires evaluating and inverting matrix <math alttext="(I-J_{\mathcal{F}})" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p5.m1" intent=":literal"><semantics><mrow><mo stretchy="false">(</mo><mrow><mi>I</mi><mo>−</mo><msub><mi>J</mi><mi class="ltx_font_mathcaligraphic">ℱ</mi></msub></mrow><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(I-J_{\mathcal{F}})</annotation></semantics></math> that can be computationally expensive. Given the Neumann series expansion,</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S2.Ex7">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="(I-J_{\mathcal{F}})^{-1}=I+J_{\mathcal{F}}+J_{\mathcal{F}}^{2}+J_{\mathcal{F}}^{3}+\dots\,," class="ltx_Math" display="block" id="S2.Ex7.m1" intent=":literal"><semantics><mrow><mrow><msup><mrow><mo stretchy="false">(</mo><mrow><mi>I</mi><mo>−</mo><msub><mi>J</mi><mi class="ltx_font_mathcaligraphic">ℱ</mi></msub></mrow><mo stretchy="false">)</mo></mrow><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo>=</mo><mrow><mi>I</mi><mo>+</mo><msub><mi>J</mi><mi class="ltx_font_mathcaligraphic">ℱ</mi></msub><mo>+</mo><msubsup><mi>J</mi><mi class="ltx_font_mathcaligraphic">ℱ</mi><mn>2</mn></msubsup><mo>+</mo><msubsup><mi>J</mi><mi class="ltx_font_mathcaligraphic">ℱ</mi><mn>3</mn></msubsup><mo>+</mo><mi mathvariant="normal">…</mi></mrow></mrow><mo lspace="0.170em">,</mo></mrow><annotation encoding="application/x-tex">(I-J_{\mathcal{F}})^{-1}=I+J_{\mathcal{F}}+J_{\mathcal{F}}^{2}+J_{\mathcal{F}}^{3}+\dots\,,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">the so-called <span class="ltx_text ltx_font_italic">1-step gradient</span> <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib37" title="">37</a></sup></cite> approximates the series by considering only its first term, i.e. <math alttext="(I-J_{\mathcal{F}})^{-1}\approx I" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p5.m2" intent=":literal"><semantics><mrow><msup><mrow><mo stretchy="false">(</mo><mrow><mi>I</mi><mo>−</mo><msub><mi>J</mi><mi class="ltx_font_mathcaligraphic">ℱ</mi></msub></mrow><mo stretchy="false">)</mo></mrow><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo>≈</mo><mi>I</mi></mrow><annotation encoding="application/x-tex">(I-J_{\mathcal{F}})^{-1}\approx I</annotation></semantics></math>, and leads to the following approximation of <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S2.E1" title="In Approximate gradient ‣ 2 Hierarchical Reasoning Model ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_tag">Equation</span>˜<span class="ltx_text ltx_ref_tag">1</span></a>:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S2.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\frac{\partial z_{H}^{*}}{\partial\theta_{H}}\approx\frac{\partial f_{H}}{\partial\theta_{H}},\quad\frac{\partial z_{H}^{*}}{\partial\theta_{L}}\approx\frac{\partial f_{H}}{\partial z^{*}_{L}}\cdot\frac{\partial z^{*}_{L}}{\partial\theta_{L}},\quad\frac{\partial z_{H}^{*}}{\partial\theta_{I}}\approx\frac{\partial f_{H}}{\partial z^{*}_{L}}\cdot\frac{\partial z^{*}_{L}}{\partial\theta_{I}}\;." class="ltx_Math" display="block" id="S2.E2.m1" intent=":literal"><semantics><mrow><mrow><mrow><mfrac><mrow><mo rspace="0em">∂</mo><msubsup><mi>z</mi><mi>H</mi><mo>∗</mo></msubsup></mrow><mrow><mo rspace="0em">∂</mo><msub><mi>θ</mi><mi>H</mi></msub></mrow></mfrac><mo>≈</mo><mfrac><mrow><mo rspace="0em">∂</mo><msub><mi>f</mi><mi>H</mi></msub></mrow><mrow><mo rspace="0em">∂</mo><msub><mi>θ</mi><mi>H</mi></msub></mrow></mfrac></mrow><mo rspace="1.167em">,</mo><mrow><mrow><mfrac><mrow><mo rspace="0em">∂</mo><msubsup><mi>z</mi><mi>H</mi><mo>∗</mo></msubsup></mrow><mrow><mo rspace="0em">∂</mo><msub><mi>θ</mi><mi>L</mi></msub></mrow></mfrac><mo>≈</mo><mrow><mfrac><mrow><mo rspace="0em">∂</mo><msub><mi>f</mi><mi>H</mi></msub></mrow><mrow><mo rspace="0em">∂</mo><msubsup><mi>z</mi><mi>L</mi><mo>∗</mo></msubsup></mrow></mfrac><mo lspace="0.222em" rspace="0.222em">⋅</mo><mfrac><mrow><mo rspace="0em">∂</mo><msubsup><mi>z</mi><mi>L</mi><mo>∗</mo></msubsup></mrow><mrow><mo rspace="0em">∂</mo><msub><mi>θ</mi><mi>L</mi></msub></mrow></mfrac></mrow></mrow><mo rspace="1.167em">,</mo><mrow><mfrac><mrow><mo rspace="0em">∂</mo><msubsup><mi>z</mi><mi>H</mi><mo>∗</mo></msubsup></mrow><mrow><mo rspace="0em">∂</mo><msub><mi>θ</mi><mi>I</mi></msub></mrow></mfrac><mo>≈</mo><mrow><mfrac><mrow><mo rspace="0em">∂</mo><msub><mi>f</mi><mi>H</mi></msub></mrow><mrow><mo rspace="0em">∂</mo><msubsup><mi>z</mi><mi>L</mi><mo>∗</mo></msubsup></mrow></mfrac><mo lspace="0.222em" rspace="0.222em">⋅</mo><mfrac><mrow><mo rspace="0em">∂</mo><msubsup><mi>z</mi><mi>L</mi><mo>∗</mo></msubsup></mrow><mrow><mo rspace="0em">∂</mo><msub><mi>θ</mi><mi>I</mi></msub></mrow></mfrac></mrow></mrow></mrow></mrow><mo>.</mo></mrow><annotation encoding="application/x-tex">\frac{\partial z_{H}^{*}}{\partial\theta_{H}}\approx\frac{\partial f_{H}}{\partial\theta_{H}},\quad\frac{\partial z_{H}^{*}}{\partial\theta_{L}}\approx\frac{\partial f_{H}}{\partial z^{*}_{L}}\cdot\frac{\partial z^{*}_{L}}{\partial\theta_{L}},\quad\frac{\partial z_{H}^{*}}{\partial\theta_{I}}\approx\frac{\partial f_{H}}{\partial z^{*}_{L}}\cdot\frac{\partial z^{*}_{L}}{\partial\theta_{I}}\;.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">The gradients of the low-level fixed point, <math alttext="\frac{\partial z^{*}_{L}}{\partial\theta_{L}}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p5.m3" intent=":literal"><semantics><mfrac><mrow><mo rspace="0em">∂</mo><msubsup><mi>z</mi><mi>L</mi><mo>∗</mo></msubsup></mrow><mrow><mo rspace="0em">∂</mo><msub><mi>θ</mi><mi>L</mi></msub></mrow></mfrac><annotation encoding="application/x-tex">\frac{\partial z^{*}_{L}}{\partial\theta_{L}}</annotation></semantics></math> and <math alttext="\frac{\partial z^{*}_{L}}{\partial\theta_{I}}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p5.m4" intent=":literal"><semantics><mfrac><mrow><mo rspace="0em">∂</mo><msubsup><mi>z</mi><mi>L</mi><mo>∗</mo></msubsup></mrow><mrow><mo rspace="0em">∂</mo><msub><mi>θ</mi><mi>I</mi></msub></mrow></mfrac><annotation encoding="application/x-tex">\frac{\partial z^{*}_{L}}{\partial\theta_{I}}</annotation></semantics></math>, can also be approximated using another application of the 1-step gradient:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S2.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\frac{\partial z^{*}_{L}}{\partial\theta_{L}}\approx\frac{\partial f_{L}}{\partial\theta_{L}},\quad\frac{\partial z^{*}_{L}}{\partial\theta_{I}}\approx\frac{\partial f_{L}}{\partial\theta_{I}}\;." class="ltx_Math" display="block" id="S2.E3.m1" intent=":literal"><semantics><mrow><mrow><mrow><mfrac><mrow><mo rspace="0em">∂</mo><msubsup><mi>z</mi><mi>L</mi><mo>∗</mo></msubsup></mrow><mrow><mo rspace="0em">∂</mo><msub><mi>θ</mi><mi>L</mi></msub></mrow></mfrac><mo>≈</mo><mfrac><mrow><mo rspace="0em">∂</mo><msub><mi>f</mi><mi>L</mi></msub></mrow><mrow><mo rspace="0em">∂</mo><msub><mi>θ</mi><mi>L</mi></msub></mrow></mfrac></mrow><mo rspace="1.167em">,</mo><mrow><mfrac><mrow><mo rspace="0em">∂</mo><msubsup><mi>z</mi><mi>L</mi><mo>∗</mo></msubsup></mrow><mrow><mo rspace="0em">∂</mo><msub><mi>θ</mi><mi>I</mi></msub></mrow></mfrac><mo>≈</mo><mfrac><mrow><mo rspace="0em">∂</mo><msub><mi>f</mi><mi>L</mi></msub></mrow><mrow><mo rspace="0em">∂</mo><msub><mi>θ</mi><mi>I</mi></msub></mrow></mfrac></mrow></mrow><mo>.</mo></mrow><annotation encoding="application/x-tex">\frac{\partial z^{*}_{L}}{\partial\theta_{L}}\approx\frac{\partial f_{L}}{\partial\theta_{L}},\quad\frac{\partial z^{*}_{L}}{\partial\theta_{I}}\approx\frac{\partial f_{L}}{\partial\theta_{I}}\;.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">By substituting <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S2.E3" title="In Approximate gradient ‣ 2 Hierarchical Reasoning Model ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_tag">Equation</span>˜<span class="ltx_text ltx_ref_tag">3</span></a> back into <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S2.E2" title="In Approximate gradient ‣ 2 Hierarchical Reasoning Model ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_tag">Equation</span>˜<span class="ltx_text ltx_ref_tag">2</span></a>, we arrive at the final simplified gradients.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px2.p6">
<p class="ltx_p">Before defining our loss function, we must first introduce two key elements of our proposed method: <span class="ltx_text ltx_font_italic">deep supervision</span> and <span class="ltx_text ltx_font_italic">adaptive computational time</span>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Deep supervision</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px3.p1">
<p class="ltx_p">Inspired by the principle that periodic neural oscillations regulate when learning occurs in the brain <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib38" title="">38</a></sup></cite>, we incorporate a deep supervision mechanism into HRM, as detailed next.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px3.p2">
<p class="ltx_p">Given a data sample <math alttext="(x,y)" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px3.p2.m1" intent=":literal"><semantics><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(x,y)</annotation></semantics></math>, we run multiple forward passes of the HRM model, each of which we refer to as a <span class="ltx_text ltx_font_italic">segment</span>. Let <math alttext="M" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px3.p2.m2" intent=":literal"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math> denote the total number of segments executed before termination. For each segment <math alttext="m\in\{1,\dots,M\}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px3.p2.m3" intent=":literal"><semantics><mrow><mi>m</mi><mo>∈</mo><mrow><mo stretchy="false">{</mo><mn>1</mn><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><mi>M</mi><mo stretchy="false">}</mo></mrow></mrow><annotation encoding="application/x-tex">m\in\{1,\dots,M\}</annotation></semantics></math>, let <math alttext="z^{m}=(z^{mNT}_{H},z^{mNT}_{L})" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px3.p2.m4" intent=":literal"><semantics><mrow><msup><mi>z</mi><mi>m</mi></msup><mo>=</mo><mrow><mo stretchy="false">(</mo><msubsup><mi>z</mi><mi>H</mi><mrow><mi>m</mi><mo lspace="0em" rspace="0em">​</mo><mi>N</mi><mo lspace="0em" rspace="0em">​</mo><mi>T</mi></mrow></msubsup><mo>,</mo><msubsup><mi>z</mi><mi>L</mi><mrow><mi>m</mi><mo lspace="0em" rspace="0em">​</mo><mi>N</mi><mo lspace="0em" rspace="0em">​</mo><mi>T</mi></mrow></msubsup><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">z^{m}=(z^{mNT}_{H},z^{mNT}_{L})</annotation></semantics></math> represent the hidden state at the conclusion of segment <math alttext="m" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px3.p2.m5" intent=":literal"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math>, encompassing both high-level and low-level state components.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px3.p3">
<p class="ltx_p">At each segment <math alttext="m" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px3.p3.m1" intent=":literal"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math>, we apply a deep supervision step as follows:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ol class="ltx_enumerate" id="S2.I2">
<li class="ltx_item" id="S2.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S2.I2.i1.p1">
<p class="ltx_p">Given the state <math alttext="z^{m-1}" class="ltx_Math" display="inline" id="S2.I2.i1.p1.m1" intent=":literal"><semantics><msup><mi>z</mi><mrow><mi>m</mi><mo>−</mo><mn>1</mn></mrow></msup><annotation encoding="application/x-tex">z^{m-1}</annotation></semantics></math> from the previous segment, compute the next state <math alttext="z^{m}" class="ltx_Math" display="inline" id="S2.I2.i1.p1.m2" intent=":literal"><semantics><msup><mi>z</mi><mi>m</mi></msup><annotation encoding="application/x-tex">z^{m}</annotation></semantics></math> and its associated output <math alttext="\hat{y}^{m}" class="ltx_Math" display="inline" id="S2.I2.i1.p1.m3" intent=":literal"><semantics><msup><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>m</mi></msup><annotation encoding="application/x-tex">\hat{y}^{m}</annotation></semantics></math> through a forward pass in the HRM model:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S2.Ex8">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="(z^{m},\hat{y}^{m})\leftarrow\textsc{HRM}(z^{m-1},x;\theta)" class="ltx_Math" display="block" id="S2.Ex8.m1" intent=":literal"><semantics><mrow><mrow><mo stretchy="false">(</mo><msup><mi>z</mi><mi>m</mi></msup><mo>,</mo><msup><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>m</mi></msup><mo stretchy="false">)</mo></mrow><mo stretchy="false">←</mo><mrow><mtext class="ltx_font_smallcaps">HRM</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msup><mi>z</mi><mrow><mi>m</mi><mo>−</mo><mn>1</mn></mrow></msup><mo>,</mo><mi>x</mi><mo>;</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">(z^{m},\hat{y}^{m})\leftarrow\textsc{HRM}(z^{m-1},x;\theta)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
</li>
<li class="ltx_item" id="S2.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S2.I2.i2.p1">
<p class="ltx_p">Compute the loss for the current segment:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S2.Ex9">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="L^{m}\leftarrow\textsc{Loss}(\hat{y}^{m},y)" class="ltx_Math" display="block" id="S2.Ex9.m1" intent=":literal"><semantics><mrow><msup><mi>L</mi><mi>m</mi></msup><mo stretchy="false">←</mo><mrow><mtext class="ltx_font_smallcaps">Loss</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msup><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>m</mi></msup><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">L^{m}\leftarrow\textsc{Loss}(\hat{y}^{m},y)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
</li>
<li class="ltx_item" id="S2.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para ltx_noindent" id="S2.I2.i3.p1">
<p class="ltx_p">Update parameters:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S2.Ex10">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\theta\leftarrow\textsc{OptimizerStep}(\theta,\nabla_{\theta}L^{m})" class="ltx_Math" display="block" id="S2.Ex10.m1" intent=":literal"><semantics><mrow><mi>θ</mi><mo stretchy="false">←</mo><mrow><mtext class="ltx_font_smallcaps">OptimizerStep</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>θ</mi><mo>,</mo><mrow><msub><mo rspace="0.167em">∇</mo><mi>θ</mi></msub><msup><mi>L</mi><mi>m</mi></msup></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\theta\leftarrow\textsc{OptimizerStep}(\theta,\nabla_{\theta}L^{m})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
</li>
</ol>
<p class="ltx_p">The crucial aspect of this procedure is that the hidden state <math alttext="z^{m}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px3.p3.m2" intent=":literal"><semantics><msup><mi>z</mi><mi>m</mi></msup><annotation encoding="application/x-tex">z^{m}</annotation></semantics></math> is “detached” from the computation graph before being used as the input state for the next segment. Consequently, gradients from segment <math alttext="m+1" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px3.p3.m3" intent=":literal"><semantics><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">m+1</annotation></semantics></math> do not propagate back through segment <math alttext="m" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px3.p3.m4" intent=":literal"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math>, effectively creating a 1-step approximation of the gradient of the recursive deep supervision process <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib39" title="">39</a></sup>, <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib40" title="">40</a></sup></cite>. This approach provides more frequent feedback to the H-module and serves as a regularization mechanism, demonstrating superior empirical performance and enhanced stability in deep equilibrium models when compared to more complex, Jacobian-based regularization techniques <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib39" title="">39</a></sup>, <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib41" title="">41</a></sup></cite>. <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S2.F4" title="In Approximate gradient ‣ 2 Hierarchical Reasoning Model ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_tag">Figure</span>˜<span class="ltx_text ltx_ref_tag">4</span></a> shows pseudocode of deep supervision training.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Adaptive computational time (ACT)</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px4.p1">
<p class="ltx_p">The brain dynamically alternates between automatic thinking (“System 1”) and deliberate reasoning (“System 2”) <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib42" title="">42</a></sup></cite>. Neuroscientific evidence shows that these cognitive modes share overlapping neural circuits, particularly within regions such as the prefrontal cortex and the default mode network <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib43" title="">43</a></sup>, <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib44" title="">44</a></sup></cite>. This indicates that the brain dynamically modulates the “runtime” of these circuits according to task complexity and potential rewards <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib45" title="">45</a></sup>, <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib46" title="">46</a></sup></cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px4.p2">
<p class="ltx_p">Inspired by the above mechanism, we incorporate an adaptive halting strategy into HRM that enables “thinking, fast and slow”. This integration leverages deep supervision and uses the Q-learning algorithm <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib47" title="">47</a></sup></cite> to adaptively determine the number of segments. A Q-head uses the final state of the H-module to predict the Q-values <math alttext="\hat{Q}^{m}=(\hat{Q}^{m}_{\text{halt}},\hat{Q}^{m}_{\text{continue}})" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px4.p2.m1" intent=":literal"><semantics><mrow><msup><mover accent="true"><mi>Q</mi><mo>^</mo></mover><mi>m</mi></msup><mo>=</mo><mrow><mo stretchy="false">(</mo><msubsup><mover accent="true"><mi>Q</mi><mo>^</mo></mover><mtext>halt</mtext><mi>m</mi></msubsup><mo>,</mo><msubsup><mover accent="true"><mi>Q</mi><mo>^</mo></mover><mtext>continue</mtext><mi>m</mi></msubsup><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\hat{Q}^{m}=(\hat{Q}^{m}_{\text{halt}},\hat{Q}^{m}_{\text{continue}})</annotation></semantics></math> of the “halt” and “continue” actions:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S2.Ex11">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\hat{Q}^{m}=\sigma(\theta_{Q}^{\top}z_{H}^{mNT})\,," class="ltx_Math" display="block" id="S2.Ex11.m1" intent=":literal"><semantics><mrow><mrow><msup><mover accent="true"><mi>Q</mi><mo>^</mo></mover><mi>m</mi></msup><mo>=</mo><mrow><mi>σ</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><msubsup><mi>θ</mi><mi>Q</mi><mo>⊤</mo></msubsup><mo lspace="0em" rspace="0em">​</mo><msubsup><mi>z</mi><mi>H</mi><mrow><mi>m</mi><mo lspace="0em" rspace="0em">​</mo><mi>N</mi><mo lspace="0em" rspace="0em">​</mo><mi>T</mi></mrow></msubsup></mrow><mo rspace="0.170em" stretchy="false">)</mo></mrow></mrow></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\hat{Q}^{m}=\sigma(\theta_{Q}^{\top}z_{H}^{mNT})\,,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">where <math alttext="\sigma" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px4.p2.m2" intent=":literal"><semantics><mi>σ</mi><annotation encoding="application/x-tex">\sigma</annotation></semantics></math> denotes the sigmoid function applied element-wise. The halt or continue action is chosen using a randomized strategy as detailed next. Let <math alttext="M_{\max}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px4.p2.m3" intent=":literal"><semantics><msub><mi>M</mi><mi>max</mi></msub><annotation encoding="application/x-tex">M_{\max}</annotation></semantics></math> denote the maximum number of segments (a fixed hyperparameter) and <math alttext="M_{\min}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px4.p2.m4" intent=":literal"><semantics><msub><mi>M</mi><mi>min</mi></msub><annotation encoding="application/x-tex">M_{\min}</annotation></semantics></math> denote the minimum number of segments (a random variable). The value of <math alttext="M_{\min}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px4.p2.m5" intent=":literal"><semantics><msub><mi>M</mi><mi>min</mi></msub><annotation encoding="application/x-tex">M_{\min}</annotation></semantics></math> is determined stochastically: with probability <math alttext="\varepsilon" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px4.p2.m6" intent=":literal"><semantics><mi>ε</mi><annotation encoding="application/x-tex">\varepsilon</annotation></semantics></math>, it is sampled uniformly from the set <math alttext="\{2,\cdots,M_{\max}\}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px4.p2.m7" intent=":literal"><semantics><mrow><mo stretchy="false">{</mo><mn>2</mn><mo>,</mo><mi mathvariant="normal">⋯</mi><mo>,</mo><msub><mi>M</mi><mi>max</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{2,\cdots,M_{\max}\}</annotation></semantics></math> (to encourage longer thinking), and with probability <math alttext="1-\varepsilon" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px4.p2.m8" intent=":literal"><semantics><mrow><mn>1</mn><mo>−</mo><mi>ε</mi></mrow><annotation encoding="application/x-tex">1-\varepsilon</annotation></semantics></math>, it is set to 1. The halt action is selected under two conditions: when the segment count surpasses the maximum threshold <math alttext="M_{\max}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px4.p2.m9" intent=":literal"><semantics><msub><mi>M</mi><mi>max</mi></msub><annotation encoding="application/x-tex">M_{\max}</annotation></semantics></math>, or when the estimated halt value <math alttext="\hat{Q}_{\text{halt}}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px4.p2.m10" intent=":literal"><semantics><msub><mover accent="true"><mi>Q</mi><mo>^</mo></mover><mtext>halt</mtext></msub><annotation encoding="application/x-tex">\hat{Q}_{\text{halt}}</annotation></semantics></math> exceeds the estimated continue value <math alttext="\hat{Q}_{\text{continue}}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px4.p2.m11" intent=":literal"><semantics><msub><mover accent="true"><mi>Q</mi><mo>^</mo></mover><mtext>continue</mtext></msub><annotation encoding="application/x-tex">\hat{Q}_{\text{continue}}</annotation></semantics></math> and the segment count has reached at least the minimum threshold <math alttext="M_{\min}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px4.p2.m12" intent=":literal"><semantics><msub><mi>M</mi><mi>min</mi></msub><annotation encoding="application/x-tex">M_{\min}</annotation></semantics></math>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px4.p3">
<p class="ltx_p">The Q-head is updated through a Q-learning algorithm, which is defined on the following episodic Markov Decision Process (MDP). The state of the MDP at segment <math alttext="m" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px4.p3.m1" intent=":literal"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math> is <math alttext="z^{m}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px4.p3.m2" intent=":literal"><semantics><msup><mi>z</mi><mi>m</mi></msup><annotation encoding="application/x-tex">z^{m}</annotation></semantics></math>, and the action space is <math alttext="\{\text{halt},\text{continue}\}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px4.p3.m3" intent=":literal"><semantics><mrow><mo stretchy="false">{</mo><mtext>halt</mtext><mo>,</mo><mtext>continue</mtext><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\text{halt},\text{continue}\}</annotation></semantics></math>. Choosing the action “halt” terminates the episode and returns a binary reward indicating prediction correctness, i.e., <math alttext="\mathbf{1}\{\hat{y}^{m}=y\}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px4.p3.m4" intent=":literal"><semantics><mrow><mn>𝟏</mn><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">{</mo><mrow><msup><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>m</mi></msup><mo>=</mo><mi>y</mi></mrow><mo stretchy="false">}</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{1}\{\hat{y}^{m}=y\}</annotation></semantics></math>. Choosing “continue” yields a reward of 0 and the state transitions to <math alttext="z^{m+1}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px4.p3.m5" intent=":literal"><semantics><msup><mi>z</mi><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow></msup><annotation encoding="application/x-tex">z^{m+1}</annotation></semantics></math>. Thus, the Q-learning targets for the two actions <math alttext="\hat{G}^{m}=(\hat{G}^{m}_{\text{halt}},\hat{G}^{m}_{\text{continue}})" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px4.p3.m6" intent=":literal"><semantics><mrow><msup><mover accent="true"><mi>G</mi><mo>^</mo></mover><mi>m</mi></msup><mo>=</mo><mrow><mo stretchy="false">(</mo><msubsup><mover accent="true"><mi>G</mi><mo>^</mo></mover><mtext>halt</mtext><mi>m</mi></msubsup><mo>,</mo><msubsup><mover accent="true"><mi>G</mi><mo>^</mo></mover><mtext>continue</mtext><mi>m</mi></msubsup><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\hat{G}^{m}=(\hat{G}^{m}_{\text{halt}},\hat{G}^{m}_{\text{continue}})</annotation></semantics></math> are given by</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A0.EGx2">
<tbody id="S2.Ex12"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\hat{G}_{\text{halt}}^{m}" class="ltx_Math" display="inline" id="S2.Ex12.m1" intent=":literal"><semantics><msubsup><mover accent="true"><mi>G</mi><mo>^</mo></mover><mtext>halt</mtext><mi>m</mi></msubsup><annotation encoding="application/x-tex">\displaystyle\hat{G}_{\text{halt}}^{m}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\mathbf{1}\{\hat{y}^{m}=y\}\,," class="ltx_Math" display="inline" id="S2.Ex12.m2" intent=":literal"><semantics><mrow><mrow><mi></mi><mo>=</mo><mrow><mn>𝟏</mn><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">{</mo><mrow><msup><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>m</mi></msup><mo>=</mo><mi>y</mi></mrow><mo rspace="0.170em" stretchy="false">}</mo></mrow></mrow></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\displaystyle=\mathbf{1}\{\hat{y}^{m}=y\}\,,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.Ex13"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\hat{G}_{\text{continue}}^{m}" class="ltx_Math" display="inline" id="S2.Ex13.m1" intent=":literal"><semantics><msubsup><mover accent="true"><mi>G</mi><mo>^</mo></mover><mtext>continue</mtext><mi>m</mi></msubsup><annotation encoding="application/x-tex">\displaystyle\hat{G}_{\text{continue}}^{m}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\begin{cases}\hat{Q}_{\text{halt}}^{m+1},&amp;\text{if $m\geq N_{\max}$}\,,\\[6.0pt]
\max(\hat{Q}_{\text{halt}}^{m+1},\hat{Q}_{\text{continue}}^{m+1})\,,&amp;\text{otherwise}\;.\end{cases}" class="ltx_Math" display="inline" id="S2.Ex13.m2" intent=":literal"><semantics><mrow><mi></mi><mo>=</mo><mrow><mo>{</mo><mtable columnspacing="5pt" rowspacing="0pt"><mtr><mtd class="ltx_align_left" columnalign="left"><mrow><msubsup><mover accent="true"><mi>Q</mi><mo>^</mo></mover><mtext>halt</mtext><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>,</mo></mrow></mtd><mtd class="ltx_align_left" columnalign="left"><mrow><mrow><mtext>if&nbsp;</mtext><mrow><mi>m</mi><mo>≥</mo><msub><mi>N</mi><mi>max</mi></msub></mrow></mrow><mo>,</mo></mrow></mtd></mtr><mtr><mtd class="ltx_align_left" columnalign="left"><mrow><mrow><mi>max</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><msubsup><mover accent="true"><mi>Q</mi><mo>^</mo></mover><mtext>halt</mtext><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>,</mo><msubsup><mover accent="true"><mi>Q</mi><mo>^</mo></mover><mtext>continue</mtext><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo rspace="0.170em" stretchy="false">)</mo></mrow></mrow><mo>,</mo></mrow></mtd><mtd class="ltx_align_left" columnalign="left"><mrow><mtext>otherwise</mtext><mo>.</mo></mrow></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">\displaystyle=\begin{cases}\hat{Q}_{\text{halt}}^{m+1},&amp;\text{if $m\geq N_{\max}$}\,,\\[6.0pt]
\max(\hat{Q}_{\text{halt}}^{m+1},\hat{Q}_{\text{continue}}^{m+1})\,,&amp;\text{otherwise}\;.\end{cases}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">We can now define the loss function of our learning procedure. The overall loss for each supervision segment combines both the Q-head loss and the sequence-to-sequence loss:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S2.Ex14">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="L^{m}_{\text{ACT}}=\textsc{Loss}(\hat{y}^{m},y)+\textsc{BinaryCrossEntropy}(\hat{Q}^{m},\hat{G}^{m})\;." class="ltx_Math" display="block" id="S2.Ex14.m1" intent=":literal"><semantics><mrow><mrow><msubsup><mi>L</mi><mtext>ACT</mtext><mi>m</mi></msubsup><mo>=</mo><mrow><mrow><mtext class="ltx_font_smallcaps">Loss</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msup><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>m</mi></msup><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow></mrow><mo>+</mo><mrow><mtext class="ltx_font_smallcaps">BinaryCrossEntropy</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msup><mover accent="true"><mi>Q</mi><mo>^</mo></mover><mi>m</mi></msup><mo>,</mo><msup><mover accent="true"><mi>G</mi><mo>^</mo></mover><mi>m</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow><annotation encoding="application/x-tex">L^{m}_{\text{ACT}}=\textsc{Loss}(\hat{y}^{m},y)+\textsc{BinaryCrossEntropy}(\hat{Q}^{m},\hat{G}^{m})\;.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">Minimizing the above loss enables both accurate predictions and nearly optimal stopping decisions.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px4.p4">
<p class="ltx_p">Selecting the “halt” action ends the supervision loop. In practice, sequences are processed in batches, which can be easily handled by substituting any halted sample in the batch with a fresh sample from the dataloader.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px4.p5">
<p class="ltx_p"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S2.F5" title="In Adaptive computational time (ACT) ‣ 2 Hierarchical Reasoning Model ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_tag">Figure</span>˜<span class="ltx_text ltx_ref_tag">5</span></a> presents a performance comparison between two HRM variants: one incorporating ACT and another employing a fixed computational step count equivalent to ACT’s <math alttext="M_{\max}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px4.p5.m1" intent=":literal"><semantics><msub><mi>M</mi><mi>max</mi></msub><annotation encoding="application/x-tex">M_{\max}</annotation></semantics></math> parameter. It shows that ACT effectively adapts its computational resources based on task complexity, achieving significant computational savings with minimal impact on performance.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S2.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="196" id="S2.F5.g1" src="./Hierarchical Reasoning Model_files/x6.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span class="ltx_text ltx_font_bold" style="font-size:90%;">Effectiveness of Adaptive Computation Time (ACT)<span class="ltx_text ltx_font_medium"> on the <span class="ltx_text ltx_font_italic">Sudoku-Extreme-Full</span>.
</span>(a)<span class="ltx_text ltx_font_medium"> Mean compute steps used by models with ACT versus models with a fixed number of compute steps (<math alttext="M" class="ltx_Math" display="inline" id="S2.F5.m6" intent=":literal"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>). ACT maintains a low and stable number of average compute steps even as the maximum limit (<math alttext="M_{\max}" class="ltx_Math" display="inline" id="S2.F5.m7" intent=":literal"><semantics><msub><mi>M</mi><mi>max</mi></msub><annotation encoding="application/x-tex">M_{\max}</annotation></semantics></math>) increases.
</span>(b)<span class="ltx_text ltx_font_medium"> Accuracy comparison. The ACT model achieves performance comparable to the fixed-compute model while utilizing substantially fewer computational steps on average.
</span>(c)<span class="ltx_text ltx_font_medium"> Inference-time scalability. Models trained with a specific <math alttext="M_{\max}" class="ltx_Math" display="inline" id="S2.F5.m8" intent=":literal"><semantics><msub><mi>M</mi><mi>max</mi></msub><annotation encoding="application/x-tex">M_{\max}</annotation></semantics></math> can generalize to higher computational limits during inference, leading to improved accuracy. For example, a model trained with <math alttext="M_{\max}=8" class="ltx_Math" display="inline" id="S2.F5.m9" intent=":literal"><semantics><mrow><msub><mi>M</mi><mi>max</mi></msub><mo>=</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">M_{\max}=8</annotation></semantics></math> continues to see accuracy gains when run with <math alttext="M_{\max}=16" class="ltx_Math" display="inline" id="S2.F5.m10" intent=":literal"><semantics><mrow><msub><mi>M</mi><mi>max</mi></msub><mo>=</mo><mn>16</mn></mrow><annotation encoding="application/x-tex">M_{\max}=16</annotation></semantics></math> during inference.</span></span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px5">
<h4 class="ltx_title ltx_title_paragraph">Inference-time scaling</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px5.p1">
<p class="ltx_p">An effective neural model should exploit additional computational resources during inference to enhance performance. As illustrated in <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S2.F5" title="In Adaptive computational time (ACT) ‣ 2 Hierarchical Reasoning Model ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_tag">Figure</span>˜<span class="ltx_text ltx_ref_tag">5</span></a>-(c), HRM seamlessly achieves inference-time scaling by simply increasing the computational limit parameter, <math alttext="M_{\max}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px5.p1.m1" intent=":literal"><semantics><msub><mi>M</mi><mi>max</mi></msub><annotation encoding="application/x-tex">M_{\max}</annotation></semantics></math> without requiring further training or architectural modifications.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px5.p2">
<p class="ltx_p">Additional compute is especially effective for tasks that demand deeper reasoning. On Sudoku—a problem that often requires long-term planning—HRM exhibits strong inference-time scaling. On the other hand, we find that extra computational resources yield minimal gains in ARC-AGI challenge, as solutions generally require only a few transformations.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px6">
<h4 class="ltx_title ltx_title_paragraph">Stability of Q-learning in ACT</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px6.p1">
<p class="ltx_p">The deep Q-learning that underpins our ACT mechanism is known to be prone to instability, often requiring stabilization techniques such as replay buffers and target networks <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib48" title="">48</a></sup></cite>, which are absent in our design. Our approach, however, achieves stability through the intrinsic properties of our model and training procedure. Recent theoretical work by <cite class="ltx_cite ltx_citemacro_citet">Gallici et al. <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib49" title="">49</a></sup></cite> shows that Q-learning can achieve convergence if network parameters are bounded, weight decay is incorporated during training, and post-normalization layers are implemented.
Our model satisfies these conditions through its Post-Norm architecture that employs RMSNorm (a layer normalization variant) and the AdamW optimizer. AdamW has been shown to solve an <math alttext="L_{\infty}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px6.p1.m1" intent=":literal"><semantics><msub><mi>L</mi><mi mathvariant="normal">∞</mi></msub><annotation encoding="application/x-tex">L_{\infty}</annotation></semantics></math>-constrained optimization problem, ensuring that model parameters remain bounded by <math alttext="1/\lambda" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px6.p1.m2" intent=":literal"><semantics><mrow><mn>1</mn><mo>/</mo><mi>λ</mi></mrow><annotation encoding="application/x-tex">1/\lambda</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib50" title="">50</a></sup></cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px7">
<h4 class="ltx_title ltx_title_paragraph">Architectural details</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px7.p1">
<p class="ltx_p">We employ a sequence-to-sequence architecture for HRM. Both input and output are represented as token sequences: <math alttext="x=(x_{1},\ldots,x_{l})" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px7.p1.m1" intent=":literal"><semantics><mrow><mi>x</mi><mo>=</mo><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>x</mi><mi>l</mi></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">x=(x_{1},\ldots,x_{l})</annotation></semantics></math> and <math alttext="y=(y_{1},\ldots,y_{l^{\prime}})" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px7.p1.m2" intent=":literal"><semantics><mrow><mi>y</mi><mo>=</mo><mrow><mo stretchy="false">(</mo><msub><mi>y</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>y</mi><msup><mi>l</mi><mo>′</mo></msup></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">y=(y_{1},\ldots,y_{l^{\prime}})</annotation></semantics></math> respectively. The model includes an embedding layer <math alttext="f_{I}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px7.p1.m3" intent=":literal"><semantics><msub><mi>f</mi><mi>I</mi></msub><annotation encoding="application/x-tex">f_{I}</annotation></semantics></math> that converts discrete tokens into vector representations, and an output head <math alttext="f_{O}(z;\theta_{O})=\text{softmax}(\theta_{O}z)" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px7.p1.m4" intent=":literal"><semantics><mrow><mrow><msub><mi>f</mi><mi>O</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>z</mi><mo>;</mo><msub><mi>θ</mi><mi>O</mi></msub><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mtext>softmax</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><msub><mi>θ</mi><mi>O</mi></msub><mo lspace="0em" rspace="0em">​</mo><mi>z</mi></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">f_{O}(z;\theta_{O})=\text{softmax}(\theta_{O}z)</annotation></semantics></math> that transforms hidden states into token probability distributions <math alttext="\hat{y}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px7.p1.m5" intent=":literal"><semantics><mover accent="true"><mi>y</mi><mo>^</mo></mover><annotation encoding="application/x-tex">\hat{y}</annotation></semantics></math>. For small-sample experiments, we replace softmax with stablemax <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib51" title="">51</a></sup></cite> to improve generalization performance. The sequence-to-sequence loss is averaged over all tokens, <math alttext="\textsc{Loss}(\hat{y},y)=\frac{1}{l^{\prime}}\sum_{i=1}^{l^{\prime}}\log p(y_{i})" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px7.p1.m6" intent=":literal"><semantics><mrow><mrow><mtext class="ltx_font_smallcaps">Loss</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><msup><mi>l</mi><mo>′</mo></msup></mfrac><mo lspace="0em" rspace="0em">​</mo><mrow><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msup><mi>l</mi><mo>′</mo></msup></msubsup><mrow><mrow><mi>log</mi><mo lspace="0.167em">⁡</mo><mi>p</mi></mrow><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow></mrow><annotation encoding="application/x-tex">\textsc{Loss}(\hat{y},y)=\frac{1}{l^{\prime}}\sum_{i=1}^{l^{\prime}}\log p(y_{i})</annotation></semantics></math>, where <math alttext="p(y_{i})" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px7.p1.m7" intent=":literal"><semantics><mrow><mi>p</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">p(y_{i})</annotation></semantics></math> is the probability that distribution <math alttext="\hat{y}_{i}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px7.p1.m8" intent=":literal"><semantics><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>i</mi></msub><annotation encoding="application/x-tex">\hat{y}_{i}</annotation></semantics></math> assigns to token <math alttext="y_{i}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px7.p1.m9" intent=":literal"><semantics><msub><mi>y</mi><mi>i</mi></msub><annotation encoding="application/x-tex">y_{i}</annotation></semantics></math>. The initial hidden states <math alttext="z^{0}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px7.p1.m10" intent=":literal"><semantics><msup><mi>z</mi><mn>0</mn></msup><annotation encoding="application/x-tex">z^{0}</annotation></semantics></math> are initialized by sampling from a truncated normal distribution with standard deviation of 1, truncation of 2, and kept fixed throughout training.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px7.p2">
<p class="ltx_p">Both the low-level and high-level recurrent modules <math alttext="f_{L}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px7.p2.m1" intent=":literal"><semantics><msub><mi>f</mi><mi>L</mi></msub><annotation encoding="application/x-tex">f_{L}</annotation></semantics></math> and <math alttext="f_{H}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px7.p2.m2" intent=":literal"><semantics><msub><mi>f</mi><mi>H</mi></msub><annotation encoding="application/x-tex">f_{H}</annotation></semantics></math> are implemented using encoder-only Transformer <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib52" title="">52</a></sup></cite> blocks with identical architectures and dimensions.
These modules take multiple inputs, and we use straightforward element-wise addition to combine them, though more sophisticated merging techniques such as gating mechanisms could potentially improve performance and is left for future work. For all Transformer blocks in this work—including those in the baseline models—we incorporate the enhancements found in modern LLMs (based on Llama <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib53" title="">53</a></sup></cite> architectures). These improvements include Rotary Positional Encoding <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib54" title="">54</a></sup></cite>, Gated Linear Units <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib55" title="">55</a></sup></cite>, RMSNorm <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib56" title="">56</a></sup></cite>, and the removal of bias terms from linear layers.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px7.p3">
<p class="ltx_p">Furthermore, both HRM and recurrent Transformer models implement a Post-Norm architecture with weights initialized via truncated LeCun Normal initialization <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib57" title="">57</a>, <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib58" title="">58</a>, <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib59" title="">59</a></sup></cite>, while the scale and bias parameters are excluded from RMSNorm. All parameters are optimized using the Adam-atan2 optimizer <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib60" title="">60</a></sup></cite>, a scale-invariant variant of Adam <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib61" title="">61</a></sup></cite>, combined with a constant learning rate that includes linear warm-up.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Results</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.p1">
<p class="ltx_p">This section begins by describing the ARC-AGI, Sudoku, and Maze benchmarks, followed by an overview of the baseline models and their results. <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S3.F6" title="In 3.1 Benchmarks ‣ 3 Results ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_tag">Figure</span>˜<span class="ltx_text ltx_ref_tag">6</span></a>-(a,b,c) presents a visual representation of the three benchmark tasks, which are selected to evaluate various reasoning abilities in AI models.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Benchmarks</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S3.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="329" id="S3.F6.g1" src="./Hierarchical Reasoning Model_files/x7.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span class="ltx_text ltx_font_bold" style="font-size:90%;">Left:<span class="ltx_text ltx_font_medium"> Visualization of benchmark tasks. </span>Right:<span class="ltx_text ltx_font_medium"> Difficulty of <span class="ltx_text ltx_font_italic">Sudoku-Extreme</span> examples.</span></span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">ARC-AGI Challenge</span>  The ARC-AGI benchmark evaluates general fluid intelligence through IQ-test-like puzzles that require inductive reasoning <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib27" title="">27</a></sup></cite>. The initial version, ARC-AGI-1, presents challenges as input-label grid pairs that force AI systems to extract and generalize abstract rules from just a few examples. Each task provides a few input–output demonstration pairs (usually 2–3) and a test input. An AI model has two attempts to produce the correct output grid. Although some believe that mastering ARC-AGI would signal true artificial general intelligence, its primary purpose is to expose the current roadblocks in AGI progress. In fact, both conventional deep learning methods and CoT techniques have faced significant challenges with ARC-AGI-1, primarily because it requires the ability to generalize to entirely new tasks <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib28" title="">28</a></sup></cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<p class="ltx_p">Addressing the limitations identified in ARC-AGI-1, ARC-AGI-2 significantly expands the benchmark by providing a more comprehensive and carefully refined collection of tasks. These new tasks emphasize deeper compositional reasoning, multi-step logic, contextual rule application, and symbolic abstraction. Human calibration studies show these tasks are challenging but doable for people, while being much harder for current AI systems, offering a clearer measure of general reasoning abilities <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib29" title="">29</a></sup></cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Sudoku-Extreme</span>  Sudoku is a 9<math alttext="\times" class="ltx_Math" display="inline" id="S3.SS1.p3.m1" intent=":literal"><semantics><mo>×</mo><annotation encoding="application/x-tex">\times</annotation></semantics></math>9 logic puzzle, requiring each row, column, and 3<math alttext="\times" class="ltx_Math" display="inline" id="S3.SS1.p3.m2" intent=":literal"><semantics><mo>×</mo><annotation encoding="application/x-tex">\times</annotation></semantics></math>3 block to contain the digits 1–9 exactly once. A prediction is considered correct if it exactly matches the puzzle’s unique solution. Sudoku’s complex logical structure makes it a popular benchmark for evaluating logical reasoning in machine learning <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib62" title="">62</a></sup>, <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib63" title="">63</a></sup>, <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib64" title="">64</a></sup></cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p4">
<p class="ltx_p">The most frequently used Sudoku dataset in research, namely the Kaggle dataset <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib65" title="">65</a></sup></cite>, can be fully solved using elementary single-digit techniques <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib66" title="">66</a></sup></cite>. The minimal 17-clue puzzles <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib62" title="">62</a></sup></cite>, another widely-used collection, might seem more challenging due to its small number of clues. However, this perception is misleading—since 17 represents the minimum number of clues required to guarantee a unique Sudoku solution, these hints need to be highly orthogonal to each other. This orthogonal arrangement leads to many direct, easily-resolved solution paths <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib67" title="">67</a></sup></cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p5">
<p class="ltx_p">We introduce <span class="ltx_text ltx_font_italic">Sudoku-Extreme</span>, a more challenging dataset that is compiled from the aforementioned easy datasets as well as puzzles recognized by the Sudoku community as exceptionally difficult for human players:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_itemize" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p">Easy puzzles compiled from Kaggle, 17-clue, plus unbiased samples from the Sudoku puzzle distribution <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib67" title="">67</a></sup></cite>: totaling <math alttext="1\,149\,158" class="ltx_Math" display="inline" id="S3.I1.i1.p1.m1" intent=":literal"><semantics><mn>1 149 158</mn><annotation encoding="application/x-tex">1\,149\,158</annotation></semantics></math> puzzles.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S3.I1.i2.p1">
<p class="ltx_p">Challenging puzzles compiled from Magictour 1465, Forum-Hard and Forum-Extreme subsets: totaling <math alttext="3\,104\,157" class="ltx_Math" display="inline" id="S3.I1.i2.p1.m1" intent=":literal"><semantics><mn>3 104 157</mn><annotation encoding="application/x-tex">3\,104\,157</annotation></semantics></math> puzzles.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
<p class="ltx_p">The compiled data then undergo a strict 90/10 train-test split, ensuring that the test set puzzles cannot be derived through equivalent transformations of any training samples. <span class="ltx_text ltx_font_italic">Sudoku-Extreme</span> is a down-sampled subset of this data containing 1000 training examples. We use <span class="ltx_text ltx_font_italic">Sudoku-Extreme</span> in our main experiments (<a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S0.F1" title="In Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_tag">Figure</span>˜<span class="ltx_text ltx_ref_tag">1</span></a>), which focuses on small-sample learning scenarios. To guarantee convergence and control overfitting effects in our analysis experiments (<a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S1.F2" title="In 1 Introduction ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_tag">Figures</span>˜<span class="ltx_text ltx_ref_tag">2</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S2.F3" title="Figure 3 ‣ Hierarchical convergence ‣ 2 Hierarchical Reasoning Model ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_tag">3</span></a> and&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S2.F5" title="Figure 5 ‣ Adaptive computational time (ACT) ‣ 2 Hierarchical Reasoning Model ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_tag">5</span></a>), we use the complete training data, <span class="ltx_text ltx_font_italic">Sudoku-Extreme-Full</span>, containing <math alttext="3\,831\,994" class="ltx_Math" display="inline" id="S3.SS1.p5.m1" intent=":literal"><semantics><mn>3 831 994</mn><annotation encoding="application/x-tex">3\,831\,994</annotation></semantics></math> examples.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p6">
<p class="ltx_p">We measure puzzle difficulty by counting the number of search backtracks (“guesses”) required by a smart Sudoku solver program <span class="ltx_text ltx_font_italic">tdoku</span>, which uses propositional logic to reduce the number of guesses <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib67" title="">67</a></sup></cite>. Our <span class="ltx_text ltx_font_italic">Sudoku-Extreme</span> dataset exhibits a mean difficulty of <math alttext="22" class="ltx_Math" display="inline" id="S3.SS1.p6.m1" intent=":literal"><semantics><mn>22</mn><annotation encoding="application/x-tex">22</annotation></semantics></math> backtracks per puzzle, significantly higher than existing datasets, including recent handmade puzzles Sudoku-Bench <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib68" title="">68</a></sup></cite> which average just <math alttext="0.45" class="ltx_Math" display="inline" id="S3.SS1.p6.m2" intent=":literal"><semantics><mn>0.45</mn><annotation encoding="application/x-tex">0.45</annotation></semantics></math> backtracks per puzzle. These subset complexity levels are shown in <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S3.F6" title="In 3.1 Benchmarks ‣ 3 Results ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_tag">Figure</span>˜<span class="ltx_text ltx_ref_tag">6</span></a>-(d).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p7">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Maze-Hard</span> This task involves finding the optimal path in a 30<math alttext="\times" class="ltx_Math" display="inline" id="S3.SS1.p7.m1" intent=":literal"><semantics><mo>×</mo><annotation encoding="application/x-tex">\times</annotation></semantics></math>30 maze, making it interpretable and frequently used for training LLMs in search tasks <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib69" title="">69</a></sup>, <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib70" title="">70</a></sup>, <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib71" title="">71</a></sup></cite>. We adopt the instance generation procedure of <cite class="ltx_cite ltx_citemacro_citet">Lehnert et al. <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib71" title="">71</a></sup></cite>, but introduce an additional filter to retain only those instances whose difficulty exceeds 110. Here, “difficulty” is defined as the length of the shortest path, which aligns with the linear time complexity of the wavefront breadth-first search algorithm on GPUs <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib72" title="">72</a></sup></cite>. A path is considered correct if it is valid and optimal—that is, the shortest route from the start to the goal. The training and test set both include 1000 examples.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Evaluation Details</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p">For all benchmarks, HRM models were initialized with random weights and trained in the sequence-to-sequence setup using the input-output pairs. The two-dimensional input and output grids were flattened and then padded to the maximum sequence length. The resulting performance is shown in <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S0.F1" title="In Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_tag">Figure</span>˜<span class="ltx_text ltx_ref_tag">1</span></a>. Remarkably, HRM attains these results with just ~1000 training examples per task—and <span class="ltx_text ltx_font_bold">without pretraining or CoT labels</span>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<p class="ltx_p">For ARC-AGI challenge, we start with (1) all demonstration and test input-label pairs from the training set, and (2) all demonstration pairs along with test inputs from the evaluation set. The dataset is augmented by applying translations, rotations, flips, and color permutations to the puzzles. Each task example is prepended with a learnable special token that represents the puzzle it belongs to. At test time, we proceed as follows for each test input in the evaluation set: (1) Generate and solve 1000 augmented variants and, for each, apply the inverse‐augmentation transform to obtain a prediction. (2) Choose the two most popular predictions as the final outputs.<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>The ARC-AGI allows two attempts for each test input.</span></span></span> All reported results are obtained by comparing the outputs with the withheld test labels from the evaluation set.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p3">
<p class="ltx_p">We augment Sudoku puzzles by applying band and digit permutations, while data augmentation is disabled for Maze tasks. Both tasks undergo only a single inference pass.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p4">
<p class="ltx_p">For ARC-AGI, the scores of the CoT models are taken from the official leaderboard <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib29" title="">29</a></sup></cite>, while for Sudoku and Maze, the scores are obtained by evaluating through the corresponding API.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p5">
<p class="ltx_p">In <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S0.F1" title="In Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_tag">Figure</span>˜<span class="ltx_text ltx_ref_tag">1</span></a>, the baselines are grouped based on whether they are pre-trained and use CoT, or neither. The “Direct pred” baseline means using “direct prediction without CoT and pre-training”, which retains the exact training setup of HRM but swaps in a Transformer architecture. Interestingly, on ARC-AGI-1, “Direct pred” matches the performance of <cite class="ltx_cite ltx_citemacro_citet">Liao and Gu <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib73" title="">73</a></sup></cite>, who built a carefully designed, domain-specific equivariant network for learning the ARC-AGI task from scratch, without pre-training. By substituting the Transformer architecture with HRM’s hierarchical framework and implementing ACT, we achieve more than a twofold performance improvement.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p6">
<p class="ltx_p">On the <span class="ltx_text ltx_font_italic">Sudoku-Extreme</span> and <span class="ltx_text ltx_font_italic">Maze-Hard</span> benchmarks, the performance gap between HRM and the baseline methods is significant, as the baselines almost never manage to solve the tasks. These benchmarks that demand lengthy reasoning traces are particularly difficult for CoT-based methods. With only 1000 training examples, the “Direct pred” baseline—which employs an 8-layer Transformer identical in size to HRM—fails entirely on these challenging reasoning problems. When trained on the larger <span class="ltx_text ltx_font_italic">Sudoku-Extreme-Full</span> dataset, however, “Direct pred” can solve some easy Sudoku puzzles and reaches <math alttext="16.9\%" class="ltx_Math" display="inline" id="S3.SS2.p6.m1" intent=":literal"><semantics><mrow><mn>16.9</mn><mo>%</mo></mrow><annotation encoding="application/x-tex">16.9\%</annotation></semantics></math> accuracy (see <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S1.F2" title="In 1 Introduction ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_tag">Figure</span>˜<span class="ltx_text ltx_ref_tag">2</span></a>). <cite class="ltx_cite ltx_citemacro_citet">Lehnert et al. <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib71" title="">71</a></sup></cite> showed that a large vanilla Transformer model with 175M parameters, trained on 1 million examples across multiple trials, achieved only marginal success on 30x30 Maze tasks, with accuracy below <math alttext="20\%" class="ltx_Math" display="inline" id="S3.SS2.p6.m2" intent=":literal"><semantics><mrow><mn>20</mn><mo>%</mo></mrow><annotation encoding="application/x-tex">20\%</annotation></semantics></math> using the <math alttext="pass@64" class="ltx_Math" display="inline" id="S3.SS2.p6.m3" intent=":literal"><semantics><mrow><mi>p</mi><mo lspace="0em" rspace="0em">​</mo><mi>a</mi><mo lspace="0em" rspace="0em">​</mo><mi>s</mi><mo lspace="0em" rspace="0em">​</mo><mi>s</mi><mo lspace="0em" rspace="0em">​</mo><mi mathvariant="normal">@</mi><mo lspace="0em" rspace="0em">​</mo><mn>64</mn></mrow><annotation encoding="application/x-tex">pass@64</annotation></semantics></math> evaluation metric.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Visualization of intermediate timesteps</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S3.F7">
<p class="ltx_p ltx_align_center"><span class="ltx_text ltx_inline-block" style="width:433.6pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="145" id="S3.F7.g1" src="./Hierarchical Reasoning Model_files/x8.png" width="913"></span>
<br class="ltx_break"><span class="ltx_text ltx_inline-block" style="width:433.6pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="113" id="S3.F7.g2" src="./Hierarchical Reasoning Model_files/x9.png" width="913"></span>
<br class="ltx_break"><span class="ltx_text ltx_inline-block" style="width:433.6pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="123" id="S3.F7.g3" src="./Hierarchical Reasoning Model_files/x10.png" width="913"></span>
<br class="ltx_break"><span class="ltx_text ltx_inline-block" style="width:433.6pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="100" id="S3.F7.g4" src="./Hierarchical Reasoning Model_files/x11.png" width="913"></span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span class="ltx_text ltx_font_bold" style="font-size:90%;">Visualization of intermediate predictions by HRM on benchmark tasks.<span class="ltx_text ltx_font_medium"> </span>Top:<span class="ltx_text ltx_font_medium"> <span class="ltx_text ltx_font_italic">Maze-Hard</span>—blue cells indicate the predicted path. </span>Middle:<span class="ltx_text ltx_font_medium"> <span class="ltx_text ltx_font_italic">Sudoku-Extreme</span>—bold cells represent initial givens; red highlights cells violating Sudoku constraints; grey shading indicates changes from the previous timestep.
</span>Bottom:<span class="ltx_text ltx_font_medium"> ARC-AGI-2 Task—left: provided example input-output pair; right: intermediate steps solving the test input.</span></span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS3.p1">
<p class="ltx_p">Although HRM demonstrates strong performance on complex reasoning tasks, it raises an intriguing question: what underlying reasoning algorithms does the HRM neural network actually implement? Addressing this question is important for enhancing model interpretability and developing a deeper understanding of the HRM solution space.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p2">
<p class="ltx_p">While a definitive answer lies beyond our current scope, we begin our investigation by analyzing state trajectories and their corresponding solution evolution. More specifically, at each timestep <math alttext="i" class="ltx_Math" display="inline" id="S3.SS3.p2.m1" intent=":literal"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math> and given the low-level and high-level state pair (<math alttext="z_{L}^{i}" class="ltx_Math" display="inline" id="S3.SS3.p2.m2" intent=":literal"><semantics><msubsup><mi>z</mi><mi>L</mi><mi>i</mi></msubsup><annotation encoding="application/x-tex">z_{L}^{i}</annotation></semantics></math> and <math alttext="z_{H}^{i}" class="ltx_Math" display="inline" id="S3.SS3.p2.m3" intent=":literal"><semantics><msubsup><mi>z</mi><mi>H</mi><mi>i</mi></msubsup><annotation encoding="application/x-tex">z_{H}^{i}</annotation></semantics></math>) we perform a preliminary forward pass through the H-module to obtain <math alttext="\bar{z}^{i}=f_{H}(z_{H}^{i},z_{L}^{i};\theta_{H})" class="ltx_Math" display="inline" id="S3.SS3.p2.m4" intent=":literal"><semantics><mrow><msup><mover accent="true"><mi>z</mi><mo>¯</mo></mover><mi>i</mi></msup><mo>=</mo><mrow><msub><mi>f</mi><mi>H</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msubsup><mi>z</mi><mi>H</mi><mi>i</mi></msubsup><mo>,</mo><msubsup><mi>z</mi><mi>L</mi><mi>i</mi></msubsup><mo>;</mo><msub><mi>θ</mi><mi>H</mi></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\bar{z}^{i}=f_{H}(z_{H}^{i},z_{L}^{i};\theta_{H})</annotation></semantics></math> and its corresponding decoded prediction <math alttext="\bar{y}^{i}=f_{O}(\bar{z}^{i};\theta_{O})" class="ltx_Math" display="inline" id="S3.SS3.p2.m5" intent=":literal"><semantics><mrow><msup><mover accent="true"><mi>y</mi><mo>¯</mo></mover><mi>i</mi></msup><mo>=</mo><mrow><msub><mi>f</mi><mi>O</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msup><mover accent="true"><mi>z</mi><mo>¯</mo></mover><mi>i</mi></msup><mo>;</mo><msub><mi>θ</mi><mi>O</mi></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\bar{y}^{i}=f_{O}(\bar{z}^{i};\theta_{O})</annotation></semantics></math>. The prediction <math alttext="\bar{y}^{i}" class="ltx_Math" display="inline" id="S3.SS3.p2.m6" intent=":literal"><semantics><msup><mover accent="true"><mi>y</mi><mo>¯</mo></mover><mi>i</mi></msup><annotation encoding="application/x-tex">\bar{y}^{i}</annotation></semantics></math> is then visualized in <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S3.F7" title="In 3.3 Visualization of intermediate timesteps ‣ 3 Results ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_tag">Figure</span>˜<span class="ltx_text ltx_ref_tag">7</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p3">
<p class="ltx_p">In the Maze task, HRM appears to initially explore several potential paths simultaneously, subsequently eliminating blocked or inefficient routes, then constructing a preliminary solution outline followed by multiple refinement iterations. In Sudoku, the strategy resembles a depth-first search approach, where the model appears to explore potential solutions and backtracks when it hits dead ends. HRM uses a different approach for ARC tasks, making incremental adjustments to the board and iteratively improving it until reaching a solution. Unlike Sudoku, which involves frequent backtracking, the ARC solution path follows a more consistent progression similar to hill-climbing optimization.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p4">
<p class="ltx_p">Importantly, the model shows that it can adapt to different reasoning approaches, likely choosing an effective strategy for each particular task. Further research is needed to gain more comprehensive insights into these solution strategies.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Brain Correspondence</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S4.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="362" id="S4.F8.g1" src="./Hierarchical Reasoning Model_files/x12.png" width="789">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span class="ltx_text" style="font-size:90%;">
<span class="ltx_text ltx_font_bold">Hierarchical Dimensionality Organization in the HRM and Mouse Cortex.</span>
(a,b) are adapted from <cite class="ltx_cite ltx_citemacro_citet">Posani et al. <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib74" title="">74</a></sup></cite>.
(a) Anatomical illustration of mouse cortical areas, color-coded by functional modules.
(b) Correlation between Participation Ratio (PR), a measure of effective neural dimensionality, and hierarchical position across different mouse cortical areas. Higher positions in the hierarchy (e.g., MOs, ACAd) exhibit significantly higher PR values compared to lower sensory areas (e.g., SSp-n), with a Spearman correlation coefficient of <math alttext="\rho" class="ltx_Math" display="inline" id="S4.F8.m8" intent=":literal"><semantics><mi>ρ</mi><annotation encoding="application/x-tex">\rho</annotation></semantics></math> = 0.79 (P = 0.0003).
(c,d) <span class="ltx_text ltx_font_bold">Trained HRM.</span>
(c) PR scaling of the trained HRM with task diversity. The dimensionality of the high-level module (<math alttext="z_{H}" class="ltx_Math" display="inline" id="S4.F8.m9" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math>) scales with the number of unique tasks (trajectories) included in the analysis, indicating an adaptive expansion of its representational capacity. In contrast, the low-level module’s (<math alttext="z_{L}" class="ltx_Math" display="inline" id="S4.F8.m10" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">z_{L}</annotation></semantics></math>) dimensionality remains stable.
(d) PR values for the low-level (<math alttext="z_{L}" class="ltx_Math" display="inline" id="S4.F8.m11" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">z_{L}</annotation></semantics></math>, PR = 30.22) and high-level (<math alttext="z_{H}" class="ltx_Math" display="inline" id="S4.F8.m12" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math>, PR = 89.95) modules of the <em class="ltx_emph ltx_font_italic">trained</em> HRM, computed from neural activity during 100 unique Sudoku-solving trajectories. A clear dimensionality hierarchy is observed, with the high-level module operating in a substantially higher-dimensional space.
(e,f) <span class="ltx_text ltx_font_bold">Analysis of Untrained Network.</span> To verify that the dimensionality hierarchy is an emergent property of training, the same analyses were performed on an <em class="ltx_emph ltx_font_italic">untrained</em> HRM with random weights.
(e) In contrast to the trained model’s scaling in (c), the dimensionality of both modules in the untrained model remains low and stable, failing to scale with the number of tasks.
(f) Similarly, contrasting with the clear separation in (d), the PR values for the untrained model’s modules (<math alttext="z_{L}" class="ltx_Math" display="inline" id="S4.F8.m13" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">z_{L}</annotation></semantics></math>, PR = 42.09; <math alttext="z_{H}" class="ltx_Math" display="inline" id="S4.F8.m14" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math>, PR = 40.75) are low and nearly identical, showing no evidence of hierarchical separation. This confirms that the observed hierarchical organization of dimensionality is a learned property that emerges through training, not an artifact of the model’s architecture.
</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.p1">
<p class="ltx_p">A key principle from systems neuroscience is that a brain region’s functional repertoire—its ability to handle diverse and complex tasks—is closely linked to the dimensionality of its neural representations <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib75" title="">75</a></sup>, <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib76" title="">76</a></sup></cite>. Higher-order cortical areas, responsible for complex reasoning and decision-making, must handle a wide variety of tasks, demanding more flexible and context-dependent processing <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib77" title="">77</a></sup></cite>. In dynamical systems, this flexibility is often realized through higher-dimensional state-space trajectories, which allow for a richer repertoire of potential computations <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib78" title="">78</a></sup></cite>. This principle gives rise to an observable <em class="ltx_emph ltx_font_italic">dimensionality hierarchy</em>, where a region’s position in the processing hierarchy correlates with its <em class="ltx_emph ltx_font_italic">effective dimensionality</em>. To quantify this phenomenon, we can examine the Participation Ratio (PR), which serves as a standard measure of the effective dimensionality of a high-dimensional representation <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib79" title="">79</a></sup></cite>. The PR is calculated using the formula</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S4.Ex15">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{PR}=\frac{(\sum_{i}\lambda_{i})^{2}}{\sum_{i}\lambda_{i}^{2}}\,," class="ltx_Math" display="block" id="S4.Ex15.m1" intent=":literal"><semantics><mrow><mrow><mtext>PR</mtext><mo>=</mo><mfrac><msup><mrow><mo stretchy="false">(</mo><mrow><msub><mo lspace="0em">∑</mo><mi>i</mi></msub><msub><mi>λ</mi><mi>i</mi></msub></mrow><mo stretchy="false">)</mo></mrow><mn>2</mn></msup><mrow><msub><mo>∑</mo><mi>i</mi></msub><msubsup><mi>λ</mi><mi>i</mi><mn>2</mn></msubsup></mrow></mfrac></mrow><mo lspace="0.170em">,</mo></mrow><annotation encoding="application/x-tex">\text{PR}=\frac{(\sum_{i}\lambda_{i})^{2}}{\sum_{i}\lambda_{i}^{2}}\,,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">where <math alttext="\{\lambda_{i}\}" class="ltx_Math" display="inline" id="S4.p1.m1" intent=":literal"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>λ</mi><mi>i</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\lambda_{i}\}</annotation></semantics></math> are the eigenvalues of the covariance matrix of neural trajectories.
Intuitively, a higher PR value signifies that variance is distributed more evenly across many dimensions, corresponding to a higher-dimensional representation. Conversely, a lower PR value indicates that variance is concentrated in only a few principal components, reflecting a more compact, lower-dimensional structure.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.p2">
<p class="ltx_p">The dimensionality hierarchy can be observed, for example, in the mouse cortex, where the PR of population activity increases monotonically from low-level sensory areas to high-level associative areas, supporting this link between dimensionality and functional complexity <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib74" title="">74</a></sup></cite> (<a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S4.F8" title="In 4 Brain Correspondence ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_tag">Figure</span>˜<span class="ltx_text ltx_ref_tag">8</span></a> (a,b)).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.p3">
<p class="ltx_p">We evaluated whether HRM reproduces this neuroscientific principle by calculating the PR for both recurrent modules after training on the <span class="ltx_text ltx_font_italic">Sudoku-Extreme Full</span> dataset. The PR computation used the covariance matrix derived from neural states gathered across multiple Sudoku-solving trajectories. The results show a striking parallel to the biological findings. The low-level module’s state (<math alttext="z_{L}" class="ltx_Math" display="inline" id="S4.p3.m1" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">z_{L}</annotation></semantics></math>) occupies a relatively small subspace with a participation ratio of 30.22, whereas the high-level module’s state (<math alttext="z_{H}" class="ltx_Math" display="inline" id="S4.p3.m2" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math>) operates in a substantially larger subspace with a participation ratio of 89.95, as shown in <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S4.F8" title="In 4 Brain Correspondence ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_tag">Figure</span>˜<span class="ltx_text ltx_ref_tag">8</span></a>(c).
Furthermore, <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S4.F8" title="In 4 Brain Correspondence ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_tag">Figure</span>˜<span class="ltx_text ltx_ref_tag">8</span></a>(d) shows that increasing the number of unique tasks (trajectories) from 10 to 100 causes <math alttext="z_{H}" class="ltx_Math" display="inline" id="S4.p3.m3" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math> dimensionality to scale up accordingly, while <math alttext="z_{L}" class="ltx_Math" display="inline" id="S4.p3.m4" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">z_{L}</annotation></semantics></math> dimensionality remains stable. These results suggest an <em class="ltx_emph ltx_font_italic">emergent</em> separation of representational capacity between the modules that parallels their functional roles.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.p4">
<p class="ltx_p">To confirm that this hierarchical organization is an emergent property of training, and not an artifact of the network’s architecture, we performed a control analysis using an identical but untrained network with random weights.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.p5">
<p class="ltx_p">We initialized an identical HRM architecture with random weights and, without any training, measured the PR of its modules as the network processed the same task-specific inputs given to the trained model.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.p6">
<p class="ltx_p">The results, shown in
<a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#S4.F8" title="In 4 Brain Correspondence ‣ Hierarchical Reasoning Model"><span class="ltx_text ltx_ref_tag">Figure</span>˜<span class="ltx_text ltx_ref_tag">8</span></a>(e,f), reveal a stark contrast: the high-level and
low-level modules of the untrained network exhibit no hierarchical separation, with their PR values
remaining low and nearly indistinguishable from each other. This control analysis validates that
the dimensionality hierarchy is an <em class="ltx_emph ltx_font_italic">emergent property</em> that arises as the model
learns to perform complex reasoning.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.p7">
<p class="ltx_p">The high-to-low PR ratio in HRM (<math alttext="z_{H}/z_{L}\approx 2.98" class="ltx_Math" display="inline" id="S4.p7.m1" intent=":literal"><semantics><mrow><mrow><msub><mi>z</mi><mi>H</mi></msub><mo>/</mo><msub><mi>z</mi><mi>L</mi></msub></mrow><mo>≈</mo><mn>2.98</mn></mrow><annotation encoding="application/x-tex">z_{H}/z_{L}\approx 2.98</annotation></semantics></math>) closely matches that measured in the mouse
cortex (<math alttext="\approx 2.25" class="ltx_Math" display="inline" id="S4.p7.m2" intent=":literal"><semantics><mrow><mi></mi><mo>≈</mo><mn>2.25</mn></mrow><annotation encoding="application/x-tex">\approx 2.25</annotation></semantics></math>). In contrast, conventional deep networks often exhibit <em class="ltx_emph ltx_font_italic">neural collapse</em>,
where last-layer features
converge to a low-dimensional
subspace <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib80" title="">80</a></sup>, <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib81" title="">81</a></sup>, <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib82" title="">82</a></sup></cite>.
HRM therefore departs from the collapse pattern and instead fosters a high-dimensional representation in its higher module. This is significant because such representations are considered crucial for cognitive flexibility and are a hallmark of higher-order brain regions like the prefrontal cortex (PFC), which is central to complex reasoning.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.p8">
<p class="ltx_p">This structural parallel suggests the model has discovered a fundamental organizational principle. By learning to partition its representations into a high-capacity, high-dimensional subspace (<math alttext="z_{H}" class="ltx_Math" display="inline" id="S4.p8.m1" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math>) and a more specialized, low-dimensional one (<math alttext="z_{L}" class="ltx_Math" display="inline" id="S4.p8.m2" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">z_{L}</annotation></semantics></math>), HRM autonomously discovers an organizational principle that is thought to be fundamental for achieving robust and flexible reasoning in biological systems. This provides a potential mechanistic explanation for the model’s success on complex, long-horizon tasks that are intractable for models lacking such a differentiated internal structure. We emphasize, however, that this evidence is correlational. While a causal link could be tested via intervention (e.g., by constraining the H-module’s dimensionality), such methods are difficult to interpret in deep learning due to potential confounding effects on the training process itself. Thus, the causal necessity of this emergent hierarchy remains an important question for future investigation.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Related Work</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Reasoning and algorithm learning</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS0.SSS0.Px1.p1">
<p class="ltx_p">Given the central role of reasoning problems and their close relation to algorithms, researchers have long explored neural architectures that enable algorithm learning from training instances. This line of work includes Neural Turing Machines (NTM) <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib83" title="">83</a></sup></cite>, the Differentiable Neural Computer (DNC) <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib84" title="">84</a></sup></cite>, and Neural GPUs <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib85" title="">85</a></sup></cite>–all of which construct iterative neural architectures that mimic computational hardware for algorithm execution, and are trained to learn algorithms from data.
Another notable work in this area is Recurrent Relational Networks (RRN) <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib62" title="">62</a></sup></cite>, which executes algorithms on graph representations through graph neural networks.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS0.SSS0.Px1.p2">
<p class="ltx_p">Recent studies have integrated algorithm learning approaches with Transformer-based architectures.
Universal Transformers extend the standard Transformer model by introducing a recurrent loop over the layers and implementing an adaptive halting mechanism. <cite class="ltx_cite ltx_citemacro_citet">Geiping et al. <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib86" title="">86</a></sup></cite> demonstrate that looped Transformers can generalize to a larger number of recurrent steps during inference than what they were trained on. <cite class="ltx_cite ltx_citemacro_citet">Shen et al. <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib16" title="">16</a></sup></cite> propose adding continuous recurrent reasoning tokens to the Transformer. Finally, TransNAR <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib8" title="">8</a></sup></cite> combine recurrent graph neural networks with language models.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS0.SSS0.Px1.p3">
<p class="ltx_p">Building on the success of CoT-based reasoning, a line of work have introduced fine-tuning methods that use reasoning paths from search algorithms (like A*) as SFT targets <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib87" title="">87</a>, <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib71" title="">71</a>, <a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib70" title="">70</a></sup></cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS0.SSS0.Px1.p4">
<p class="ltx_p">We also mention adaptive halting mechanisms designed to allocate additional computational resources to more challenging problems. This includes the Adaptive Computation Time (ACT) for RNNs <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib88" title="">88</a></sup></cite> and follow-up research like PonderNet <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib89" title="">89</a></sup></cite>, which aims to improve the stability of this allocation process.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS0.SSS0.Px1.p5">
<p class="ltx_p">HRM further pushes the boundary of algorithm learning through a brain-inspired computational architecture that achieves exceptional data efficiency and model expressiveness, successfully discovering complex and diverse algorithms from just 1000 training examples.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Brain-inspired reasoning architectures</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS0.SSS0.Px2.p1">
<p class="ltx_p">Developing a model with the reasoning power of the brain has long been a goal in brain-inspired computing.
Spaun <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib90" title="">90</a></sup></cite> is one notable example, which uses spiking neural networks to create distinct modules corresponding to brain regions like the visual cortex and prefrontal cortex. This design enables an architecture to perform a range of cognitive tasks, from memory recall to simple reasoning puzzles. However, its reasoning relies on hand-designed algorithms, which may limit its ability to learn new tasks.
Another significant model is the Tolman-Eichenbaum Machine (TEM) <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib91" title="">91</a></sup></cite>, which is inspired by the hippocampal-entorhinal system’s role in spatial and relational memory tasks. TEM proposes that medial entorhinal cells create a basis for structural knowledge, while hippocampal cells link this basis to sensory information. This allows TEM to generalize and explains the emergence of various cell types like grid, border, and place cells.
Another approach involves neural sampling models <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib92" title="">92</a></sup></cite>, which view the neural signaling process as inference over a distribution, functioning similarly to a Boltzmann machine. These models often require hand-made rules to be set up for solving a specific reasoning task.
In essence, while prior models are restricted to simple reasoning problems, HRM is designed to solve complex tasks that are hard for even advanced LLMs, without pre-training or task-specific manual design.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Hierarchical memory</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS0.SSS0.Px3.p1">
<p class="ltx_p">The hierarchical multi-timescale structure also plays an important role in how the brain processes memory. Models such as Hierarchical Sequential Models <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib93" title="">93</a></sup></cite> and Clockwork RNN <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib94" title="">94</a></sup></cite> use multiple recurrent modules that operate at varying time scales to more effectively capture long-range dependencies within sequences, thereby mitigating the forgetting issue in RNNs.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS0.SSS0.Px3.p2">
<p class="ltx_p">Similar mechanisms have also been adopted in linear attention methods for memorizing long contexts (see the Discussions section).
Since HRM focuses on reasoning, full attention is applied for simplicity. Incorporating hierarchical memory into HRM could be a promising future direction.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Discussions</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S6.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Turing-completeness of HRM</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S6.SS0.SSS0.Px1.p1">
<p class="ltx_p">Like earlier neural reasoning algorithms including the Universal Transformer <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib95" title="">95</a></sup></cite>, HRM is computationally universal when given sufficient memory and time constraints. In other words, it falls into the category of models that can simulate any Turing machine, overcoming the computational limitations of standard Transformers discussed previously in the introduction. Given that earlier neural algorithm reasoners were trained as recurrent neural networks, they suffer from premature convergence and memory intensive BPTT. Therefore, in practice, their effective computational depth remains limited, though still deeper than that of a standard Transformer. By resolving these two challenges and being equipped with adaptive computation, HRM could be trained on long reasoning processes, solve complex puzzles requiring intensive depth-first search and backtracking, and move closer to practical Turing-completeness.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S6.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Reinforcement learning with chain-of-thought</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S6.SS0.SSS0.Px2.p1">
<p class="ltx_p">Beyond fine-tuning using human-annotated CoT, reinforcement learning (RL) represents another widely adopted training methodology.
However, recent evidence suggests that RL primarily unlocks existing CoT-like capabilities rather than discovering fundamentally new reasoning mechanisms <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib96" title="">96</a></sup>, <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib97" title="">97</a></sup>, <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib98" title="">98</a></sup>, <sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib99" title="">99</a></sup></cite>.
Additionally, CoT-training with RL is known for its instability and data inefficiency, often requiring extensive exploration and careful reward design. In contrast, HRM takes feedback from dense gradient-based supervision rather than relying on a sparse reward signal. Moreover, HRM
operates naturally in a continuous space, which is biologically plausible and avoids allocating same computational resources to each token, even though tokens vary in their reasoning and planning complexity <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib16" title="">16</a></sup></cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S6.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Linear attention</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S6.SS0.SSS0.Px3.p1">
<p class="ltx_p">Recurrence has been explored not only for its capability in universal computation, but also as a means to replace the attention mechanism in Transformers, which suffers from quadratic time and memory complexity <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib100" title="">100</a></sup></cite>. Recurrent alternatives offer a more efficient design by processing input tokens sequentially and predicting the next token at each time step, similar to early RNN-based language models.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S6.SS0.SSS0.Px3.p2">
<p class="ltx_p">Some linear-attention variants, such as Log-linear Attention <cite class="ltx_cite ltx_citemacro_cite"><sup class="ltx_sup"><a class="ltx_ref" href="https://arxiv.org/html/2506.21734v3#bib.bib101" title="">101</a></sup></cite>, share an RNN-like state-update that can be interpreted as propagating multi-timescale summary statistics, thereby retaining long-range context without the quadratic memory growth of standard self-attention.
However, substituting the attention mechanism alone does not change the fact that Transformers are still fixed-depth, and require CoT as a compensatory mechanism. Notably, linear attention can operate with a reduced key-value cache over extended contexts, making them more suitable for deployment on resource-constrained edge devices.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S7.p1">
<p class="ltx_p">This work introduces the Hierarchical Reasoning Model, a brain-inspired architecture that leverages hierarchical structure and multi-timescale processing to achieve substantial computational depth without sacrificing training stability or efficiency. With only 27M parameters and training on just 1000 examples, HRM effectively solves challenging reasoning problems such as ARC, Sudoku, and complex maze navigation–tasks that typically pose significant difficulties for contemporary LLM and chain-of-thought models.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S7.p2">
<p class="ltx_p">Although the brain relies heavily on hierarchical structures to enable most cognitive processes, these concepts have largely remained confined to academic literature rather than being translated into practical applications.
The prevailing AI approach continues to favor non-hierarchical models. Our results challenge this established paradigm and suggest that the Hierarchical Reasoning Model represents a viable alternative to the currently dominant chain-of-thought reasoning methods, advancing toward a foundational framework capable of Turing-complete universal computation.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S7.p3">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Acknowledgements</span> We thank Mingli Yuan, Ahmed Murtadha Hasan Mahyoub and Hengshuai Yao for their insightful discussions and valuable feedback throughout the course of this work.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodfellow et al. 2016<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ian Goodfellow, Yoshua Bengio, and Aaron Courville.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Deep Learning</em>.

</span>
<span class="ltx_bibblock">MIT Press, 2016.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="http://www.deeplearningbook.org/" title="">http://www.deeplearningbook.org</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. 2015<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kaiming He, X. Zhang, Shaoqing Ren, and Jian Sun.

</span>
<span class="ltx_bibblock">Deep residual learning for image recognition.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, pages 770–778, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Strobl 2023<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lena Strobl.

</span>
<span class="ltx_bibblock">Average-hard attention transformers are constant-depth uniform threshold circuits, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bylander 1991<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tom Bylander.

</span>
<span class="ltx_bibblock">Complexity results for planning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Proceedings of the 12th International Joint Conference on Artificial Intelligence - Volume 1</em>, IJCAI’91, page 274–279, San Francisco, CA, USA, 1991. Morgan Kaufmann Publishers Inc.

</span>
<span class="ltx_bibblock">ISBN 1558601600.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Merrill and Sabharwal 2023a<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
William Merrill and Ashish Sabharwal.

</span>
<span class="ltx_bibblock">A logic for expressing log-precision transformers.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Neural Information Processing Systems</em>, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chiang 2025<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
David Chiang.

</span>
<span class="ltx_bibblock">Transformers in DLOGTIME-uniform <math alttext="\text{TC}^{0}" class="ltx_Math" display="inline" id="bib.bib6.m1" intent=":literal"><semantics><msup><mtext>TC</mtext><mn>0</mn></msup><annotation encoding="application/x-tex">\text{TC}^{0}</annotation></semantics></math>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Transactions on Machine Learning Research</em>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lehnert et al. 2024a<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lucas Lehnert, Sainbayar Sukhbaatar, DiJia Su, Qinqing Zheng, Paul McVay, Michael Rabbat, and Yuandong Tian.

</span>
<span class="ltx_bibblock">Beyond a*: Better planning with transformers via search dynamics bootstrapping.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">First Conference on Language Modeling</em>, 2024a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bounsi et al. 2024<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wilfried Bounsi, Borja Ibarz, Andrew Dudzik, Jessica B. Hamrick, Larisa Markeeva, Alex Vitvitskyi, Razvan Pascanu, and Petar Velivckovi’c.

</span>
<span class="ltx_bibblock">Transformers meet neural algorithmic reasoners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2406.09308, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Merrill and Sabharwal 2023b<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
William Merrill and Ashish Sabharwal.

</span>
<span class="ltx_bibblock">The parallelism tradeoff: Limitations of log-precision transformers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>, 11:531–545, 2023b.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1162/tacl_a_00562</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. 2022<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jason Wei, Yi Tay, et al.

</span>
<span class="ltx_bibblock">Chain-of-thought prompting elicits reasoning in large language models, 2022.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2201.11903.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Merrill and Sabharwal 2024<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
William Merrill and Ashish Sabharwal.

</span>
<span class="ltx_bibblock">The expressive power of transformers with chain of thought.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">ICLR</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. 2024<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xinyun Chen, Ryan A. Chi, Xuezhi Wang, and Denny Zhou.

</span>
<span class="ltx_bibblock">Premise order matters in reasoning with large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2402.08939, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. 2024<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rongwu Xu, Zehan Qi, and Wei Xu.

</span>
<span class="ltx_bibblock">Preemptive answer "attacks" on chain-of-thought reasoning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Annual Meeting of the Association for Computational Linguistics</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Villalobos et al. 2022<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Pablo Villalobos, Anson Ho, Jaime Sevilla, Tamay Besiroglu, Lennart Heim, and Marius Hobbhahn.

</span>
<span class="ltx_bibblock">Will we run out of data? limits of llm scaling based on human-generated data.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2211.04325</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. 2025<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xinghao Chen, Anhao Zhao, Heming Xia, Xuan Lu, Hanlin Wang, Yanjun Chen, Wei Zhang, Jian Wang, Wenjie Li, and Xiaoyu Shen.

</span>
<span class="ltx_bibblock">Reasoning beyond language: A comprehensive survey on latent chain-of-thought reasoning, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen et al. 2024<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xuan Shen, Yizhou Wang, Xiangxi Shi, Yanzhi Wang, Pu Zhao, and Jiuxiang Gu.

</span>
<span class="ltx_bibblock">Training large language models to reason in a continuous latent space.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2412.07423</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fedorenko et al. 2024<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Evelina Fedorenko, Steven T Piantadosi, and Edward AF Gibson.

</span>
<span class="ltx_bibblock">Language is primarily a tool for communication rather than thought.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Nature</em>, 630(8017):575–586, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. 2024<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hongyu Wang, Shuming Ma, Li Dong, Shaohan Huang, Dongdong Zhang, and Furu Wei.

</span>
<span class="ltx_bibblock">Deepnet: Scaling transformers to 1,000 layers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lillicrap and Santoro 2019<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Timothy P Lillicrap and Adam Santoro.

</span>
<span class="ltx_bibblock">Backpropagation through time and the brain.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Current Opinion in Neurobiology</em>, 55:82–89, 2019.

</span>
<span class="ltx_bibblock">ISSN 0959-4388.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">https://doi.org/10.1016/j.conb.2019.01.011</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Murray et al. 2014<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
John D Murray, Alberto Bernacchia, David J Freedman, Ranulfo Romo, Jonathan D Wallis, Xinying Cai, Camillo Padoa-Schioppa, Tatiana Pasternak, Hyojung Seo, Daeyeol Lee, et al.

</span>
<span class="ltx_bibblock">A hierarchy of intrinsic timescales across primate cortex.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Nature neuroscience</em>, 17(12):1661–1663, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeraati et al. 2023<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Roxana Zeraati, Yan-Liang Shi, Nicholas A Steinmetz, Marc A Gieselmann, Alexander Thiele, Tirin Moore, Anna Levina, and Tatiana A Engel.

</span>
<span class="ltx_bibblock">Intrinsic timescales in the visual cortex change with selective attention and reflect spatial connectivity.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Nature communications</em>, 14(1):1858, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huntenburg et al. 2018<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Julia M Huntenburg, Pierre-Louis Bazin, and Daniel S Margulies.

</span>
<span class="ltx_bibblock">Large-scale gradients in human cortical organization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Trends in cognitive sciences</em>, 22(1):21–31, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lamme and Roelfsema 2000<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Victor AF Lamme and Pieter R Roelfsema.

</span>
<span class="ltx_bibblock">The distinct modes of vision offered by feedforward and recurrent processing.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Trends in neurosciences</em>, 23(11):571–579, 2000.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bastos et al. 2012<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Andre M Bastos, W Martin Usrey, Rick A Adams, George R Mangun, Pascal Fries, and Karl J Friston.

</span>
<span class="ltx_bibblock">Canonical microcircuits for predictive coding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Neuron</em>, 76(4):695–711, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kaleb et al. 2024<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Klara Kaleb, Barbara Feulner, Juan Gallego, and Claudia Clopath.

</span>
<span class="ltx_bibblock">Feedback control guides credit assignment in recurrent neural networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 37:5122–5144, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lillicrap et al. 2020<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Timothy P Lillicrap, Adam Santoro, Luke Marris, Colin J Akerman, and Geoffrey Hinton.

</span>
<span class="ltx_bibblock">Backpropagation and the brain.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Nature Reviews Neuroscience</em>, 21(6):335–346, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chollet 2019<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
François Chollet.

</span>
<span class="ltx_bibblock">On the measure of intelligence (abstraction and reasoning corpus), 2019.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1911.01547.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chollet et al. 2024<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Francois Chollet, Mike Knoop, Gregory Kamradt, and Bryan Landers.

</span>
<span class="ltx_bibblock">Arc prize 2024: Technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2412.04604, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chollet et al. 2025<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Francois Chollet, Mike Knoop, Gregory Kamradt, Bryan Landers, and Henry Pinkard.

</span>
<span class="ltx_bibblock">Arc-agi-2: A new challenge for frontier ai reasoning systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2505.11831</em>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Buzsáki 2000<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
György Buzsáki.

</span>
<span class="ltx_bibblock">Gamma, alpha, delta, and theta oscillations govern cognitive processes.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">International Journal of Psychophysiology</em>, 39:241–248, 2000.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Buzsáki 2006<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
György Buzsáki.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Rhythms of the Brain</em>.

</span>
<span class="ltx_bibblock">Oxford university press, 2006.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pahor and Jaušovec 2014<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Anja Pahor and Norbert Jaušovec.

</span>
<span class="ltx_bibblock">Theta–gamma cross-frequency coupling relates to the level of human intelligence.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Intelligence</em>, 46:283–290, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tort et al. 2009<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Adriano BL Tort, Robert W Komorowski, Joseph R Manns, Nancy J Kopell, and Howard Eichenbaum.

</span>
<span class="ltx_bibblock">Theta–gamma coupling increases during the learning of item–context associations.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Proceedings of the National Academy of Sciences</em>, 106(49):20942–20947, 2009.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scellier and Bengio 2016<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Benjamin Scellier and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Equilibrium propagation: Bridging the gap between energy-based models and backpropagation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Frontiers in Computational Neuroscience</em>, 11, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bellec et al. 2020<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Guillaume Bellec, Franz Scherr, Anand Subramoney, Elias Hajek, Darjan Salaj, Robert Legenstein, and Wolfgang Maass.

</span>
<span class="ltx_bibblock">A solution to the learning dilemma for recurrent networks of spiking neurons.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Nature Communications</em>, 11, 07 2020.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1038/s41467-020-17236-y</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et al. 2019<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shaojie Bai, J Zico Kolter, and Vladlen Koltun.

</span>
<span class="ltx_bibblock">Deep equilibrium models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, pages 690–701, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geng et al. 2021<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhengyang Geng, Xinyu Zhang, Shaojie Bai, Yisen Wang, and Zhouchen Lin.

</span>
<span class="ltx_bibblock">On training implicit models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2111.05177, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Begus and Bonawitz 2020<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Katarina Begus and Elizabeth Bonawitz.

</span>
<span class="ltx_bibblock">The rhythm of learning: Theta oscillations as an index of active learning in infancy.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Developmental Cognitive Neuroscience</em>, 45:100810, 2020.

</span>
<span class="ltx_bibblock">ISSN 1878-9293.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">https://doi.org/10.1016/j.dcn.2020.100810</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et al. 2022<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shaojie Bai, Zhengyang Geng, Yash Savani, and J. Zico Kolter.

</span>
<span class="ltx_bibblock"> Deep Equilibrium Optical Flow Estimation .

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, pages 610–620, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramzi et al. 2021<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zaccharie Ramzi, Florian Mannel, Shaojie Bai, Jean-Luc Starck, Philippe Ciuciu, and Thomas Moreau.

</span>
<span class="ltx_bibblock">Shine: Sharing the inverse estimate from the forward pass for bi-level optimization and implicit models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2106.00553, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et al. 2021<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shaojie Bai, Vladlen Koltun, and J. Zico Kolter.

</span>
<span class="ltx_bibblock">Stabilizing equilibrium models by jacobian regularization.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kahneman and Egan 2011<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Daniel Kahneman and P Egan.

</span>
<span class="ltx_bibblock">Thinking, fast and slow (farrar, straus and giroux, new york), 2011.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lieberman 2007<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Matthew D Lieberman.

</span>
<span class="ltx_bibblock">Social cognitive neuroscience: a review of core processes.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Annu. Rev. Psychol.</em>, 58(1):259–289, 2007.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Buckner et al. 2008<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Randy L Buckner, Jessica R Andrews-Hanna, and Daniel L Schacter.

</span>
<span class="ltx_bibblock">The brain’s default network: anatomy, function, and relevance to disease.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Annals of the new York Academy of Sciences</em>, 1124(1):1–38, 2008.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raichle 2015<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Marcus E Raichle.

</span>
<span class="ltx_bibblock">The brain’s default mode network.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Annual review of neuroscience</em>, 38(1):433–447, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Westbrook and Braver 2015<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Andrew Westbrook and Todd S Braver.

</span>
<span class="ltx_bibblock">Cognitive effort: A neuroeconomic approach.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Cognitive, Affective, &amp; Behavioral Neuroscience</em>, 15:395–415, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sutton and Barto 2018<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Richard S. Sutton and Andrew G. Barto.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Reinforcement Learning: An Introduction</em>.

</span>
<span class="ltx_bibblock">MIT Press, Cambridge, MA, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mnih et al. 2013<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, and Martin A. Riedmiller.

</span>
<span class="ltx_bibblock">Playing atari with deep reinforcement learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">ArXiv</em>, abs/1312.5602, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gallici et al. 2025<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Matteo Gallici, Mattie Fellows, Benjamin Ellis, Bartomeu Pou, Ivan Masmitja, Jakob Nicolaus Foerster, and Mario Martin.

</span>
<span class="ltx_bibblock">Simplifying deep temporal difference learning, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie and Li 2024<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shuo Xie and Zhiyuan Li.

</span>
<span class="ltx_bibblock">Implicit bias of adamw: L inf norm constrained optimization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2404.04454, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Prieto et al. 2025<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lucas Prieto, Melih Barsbey, Pedro A. M. Mediano, and Tolga Birdal.

</span>
<span class="ltx_bibblock">Grokking at the edge of numerical stability.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">The Thirteenth International Conference on Learning Representations</em>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al. 2017<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, pages 5998–6008, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meta AI 2024<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Meta AI.

</span>
<span class="ltx_bibblock">Llama 3: State-of-the-art open weight language models.

</span>
<span class="ltx_bibblock">Technical report, Meta, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ai.meta.com/llama/" title="">https://ai.meta.com/llama/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su et al. 2024<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jianlin Su, Murtadha Ahmed, Yu Lu, Shengfeng Pan, Wen Bo, and Yunfeng Liu.

</span>
<span class="ltx_bibblock">Roformer: Enhanced transformer with rotary position embedding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Neurocomputing</em>, 568:127063, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shazeer 2020<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Noam M. Shazeer.

</span>
<span class="ltx_bibblock">Glu variants improve transformer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2002.05202, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang and Sennrich 2019<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Biao Zhang and Rico Sennrich.

</span>
<span class="ltx_bibblock">Root mean square layer normalization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">ArXiv</em>, abs/1910.07467, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Klambauer et al. 2017<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Günter Klambauer, Thomas Unterthiner, Andreas Mayr, and Sepp Hochreiter.

</span>
<span class="ltx_bibblock">Self-normalizing neural networks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Neural Information Processing Systems</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">JAX Developers 2025<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
JAX Developers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">jax.nn.initializers.lecun_normal</em>.

</span>
<span class="ltx_bibblock">Google Research, 2025.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://docs.jax.dev/en/latest/_autosummary/jax.nn.initializers.lecun_normal.html" title="">https://docs.jax.dev/en/latest/_autosummary/jax.nn.initializers.lecun_normal.html</a>.

</span>
<span class="ltx_bibblock">Accessed June 22, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">LeCun et al. 2002<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yann LeCun, Léon Bottou, Genevieve B Orr, and Klaus-Robert Müller.

</span>
<span class="ltx_bibblock">Efficient backprop.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Neural networks: Tricks of the trade</em>, pages 9–50. Springer, 2002.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Everett et al. 2024<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Katie E Everett, Lechao Xiao, Mitchell Wortsman, Alexander A Alemi, Roman Novak, Peter J Liu, Izzeddin Gur, Jascha Sohl-Dickstein, Leslie Pack Kaelbling, Jaehoon Lee, and Jeffrey Pennington.

</span>
<span class="ltx_bibblock">Scaling exponents across parameterizations and optimizers.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Forty-first International Conference on Machine Learning</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma and Ba 2017<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Diederik P. Kingma and Jimmy Ba.

</span>
<span class="ltx_bibblock">Adam: A method for stochastic optimization, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Palm et al. 2017<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rasmus Berg Palm, Ulrich Paquet, and Ole Winther.

</span>
<span class="ltx_bibblock">Recurrent relational networks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Neural Information Processing Systems</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Long 2023<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jieyi Long.

</span>
<span class="ltx_bibblock">Large language model guided tree-of-thought.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2305.08291, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du et al. 2024<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yilun Du, Jiayuan Mao, and Josh Tenenbaum.

</span>
<span class="ltx_bibblock">Learning iterative reasoning through energy diffusion.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2406.11179, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park 2018<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kyubyong Park.

</span>
<span class="ltx_bibblock">Can convolutional neural networks crack sudoku puzzles?

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/Kyubyong/sudoku" title="">https://github.com/Kyubyong/sudoku</a>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">66<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Single-digit techniques.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hodoku.sourceforge.net/en/tech_singles.php" title="">https://hodoku.sourceforge.net/en/tech_singles.php</a>.

</span>
<span class="ltx_bibblock">Accessed: 2025-06-16.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dillion 2025<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tom Dillion.

</span>
<span class="ltx_bibblock">Tdoku: A fast sudoku solver and generator.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://t-dillon.github.io/tdoku/" title="">https://t-dillon.github.io/tdoku/</a>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Seely et al. 2025<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jeffrey Seely, Yuki Imajuku, Tianyu Zhao, Edoardo Cetin, and Llion Jones.

</span>
<span class="ltx_bibblock">Sudoku-bench: Evaluating creative reasoning with sudoku variants.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2505.16135</em>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Darlow et al. 2025<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Luke Darlow, Ciaran Regan, Sebastian Risi, Jeffrey Seely, and Llion Jones.

</span>
<span class="ltx_bibblock">Continuous thought machines.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2505.05522</em>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su et al. 2025<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
DiJia Su, Sainbayar Sukhbaatar, Michael Rabbat, Yuandong Tian, and Qinqing Zheng.

</span>
<span class="ltx_bibblock">Dualformer: Controllable fast and slow thinking by learning with randomized reasoning traces, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lehnert et al. 2024b<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lucas Lehnert, Sainbayar Sukhbaatar, DiJia Su, Qinqing Zheng, Paul McVay, Michael Rabbat, and Yuandong Tian.

</span>
<span class="ltx_bibblock">Beyond a*: Better planning with transformers via search dynamics bootstrapping.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">First Conference on Language Modeling</em>, 2024b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kapadia et al. 2013<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Mubbasir Kapadia, Francisco Garcia, Cory D. Boatright, and Norman I. Badler.

</span>
<span class="ltx_bibblock">Dynamic search on the gpu.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">2013 IEEE/RSJ International Conference on Intelligent Robots and Systems</em>, pages 3332–3337, 2013.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/IROS.2013.6696830</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liao and Gu 2025<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Isaac Liao and Albert Gu.

</span>
<span class="ltx_bibblock">Arc-agi without pretraining, 2025.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://iliao2345.github.io/blog_posts/arc_agi_without_pretraining/arc_agi_without_pretraining.html" title="">https://iliao2345.github.io/blog_posts/arc_agi_without_pretraining/arc_agi_without_pretraining.html</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Posani et al. 2025<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lorenzo Posani, Shuqi Wang, Samuel P Muscinelli, Liam Paninski, and Stefano Fusi.

</span>
<span class="ltx_bibblock">Rarely categorical, always high-dimensional: how the neural code changes along the cortical hierarchy.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">bioRxiv</em>, pages 2024–11, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rigotti et al. 2013<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Mattia Rigotti, Omri Barak, Melissa R. Warden, Xiao-Jing Wang, Nathaniel D. Daw, Earl K. Miller, and Stefano Fusi.

</span>
<span class="ltx_bibblock">The importance of mixed selectivity in complex cognitive tasks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Nature</em>, 497:585–590, 2013.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1038/nature12160</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mante et al. 2013<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Valerio Mante, David Sussillo, Krishna V. Shenoy, and William T. Newsome.

</span>
<span class="ltx_bibblock">Context-dependent computation by recurrent dynamics in prefrontal cortex.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Nature</em>, 503(7474):78–84, 2013.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1038/nature12742</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Miller and Cohen 2001<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Earl K. Miller and Jonathan D. Cohen.

</span>
<span class="ltx_bibblock">An integrative theory of prefrontal cortex function.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Annual Review of Neuroscience</em>, 24(1):167–202, 2001.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1146/annurev.neuro.24.1.167</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Maass 2002<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wolfgang Maass.

</span>
<span class="ltx_bibblock">Real-time computing without stable states: a new framework for neural computation based on perturbations.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Neural Computation</em>, 14(11):2531–2560, 2002.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1162/089976602760407955</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Altan et al. 2021<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ege Altan, Sara A. Solla, Lee E. Miller, and Eric J. Perreault.

</span>
<span class="ltx_bibblock">Estimating the dimensionality of the manifold underlying multi-electrode neural recordings.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">PLoS Computational Biology</em>, 17(11):e1008591, 2021.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1371/journal.pcbi.1008591</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papyan et al. 2020<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Vardan Papyan, X. Y. Han, and David L. Donoho.

</span>
<span class="ltx_bibblock">Prevalence of neural collapse during the terminal phase of deep learning training.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Proceedings of the National Academy of Sciences</em>, 117(40):24652–24663, 2020.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1073/pnas.2015509117</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fang et al. 2021<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Cong Fang, Hangfeng He, Qi Long, and Weijie J. Su.

</span>
<span class="ltx_bibblock">Exploring deep neural networks via layer–peeled model: Minority collapse in imbalanced training.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Proceedings of the National Academy of Sciences</em>, 118(43):e2103091118, 2021.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1073/pnas.2103091118</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib82">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. 2021<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhihui Zhu, Tianyu Ding, Jinxin Zhou, Xiao Li, Chong You, Jeremias Sulam, and Qing Qu.

</span>
<span class="ltx_bibblock">A geometric analysis of neural collapse with unconstrained features.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, volume 34 of <em class="ltx_emph ltx_font_italic">NeurIPS</em>, pages 29820–29834, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib83">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Graves et al. 2014<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Alex Graves, Greg Wayne, and Ivo Danihelka.

</span>
<span class="ltx_bibblock">Neural turing machines, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib84">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Graves et al. 2016<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Alex Graves, Greg Wayne, Malcolm Reynolds, Tim Harley, Ivo Danihelka, Agnieszka Grabska-Barwińska, Sergio Gómez Colmenarejo, Edward Grefenstette, Tiago Ramalho, John Agapiou, et al.

</span>
<span class="ltx_bibblock">Hybrid computing using a neural network with dynamic external memory.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Nature</em>, 538(7626):471–476, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib85">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kaiser and Sutskever 2016<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lukasz Kaiser and Ilya Sutskever.

</span>
<span class="ltx_bibblock">Neural GPUs learn algorithms.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">ICLR</em>, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib86">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geiping et al. 2025<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jonas Geiping, Sean McLeish, Neel Jain, John Kirchenbauer, Siddharth Singh, Brian R. Bartoldson, Bhavya Kailkhura, Abhinav Bhatele, and Tom Goldstein.

</span>
<span class="ltx_bibblock">Scaling up test-time compute with latent reasoning: A recurrent depth approach, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib87">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu and Low 2023<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tiedong Liu and Kian Hsiang Low.

</span>
<span class="ltx_bibblock">Goat: Fine-tuned llama outperforms gpt-4 on arithmetic tasks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2305.14201, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib88">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Graves 2016<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Alex Graves.

</span>
<span class="ltx_bibblock">Adaptive computation time for recurrent neural networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">ArXiv</em>, abs/1603.08983, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib89">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Banino et al. 2021<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Andrea Banino, Jan Balaguer, and Charles Blundell.

</span>
<span class="ltx_bibblock">Pondernet: Learning to ponder.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2107.05407, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib90">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eliasmith et al. 2012<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chris Eliasmith, Terrence C Stewart, Xuan Choo, Trevor Bekolay, Travis DeWolf, Yichuan Tang, and Daniel Rasmussen.

</span>
<span class="ltx_bibblock">A large-scale model of the functioning brain.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">science</em>, 338(6111):1202–1205, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib91">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Whittington et al. 2020<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
James CR Whittington, Timothy H Muller, Shirley Mark, Guifen Chen, Caswell Barry, Neil Burgess, and Timothy EJ Behrens.

</span>
<span class="ltx_bibblock">The tolman-eichenbaum machine: unifying space and relational memory through generalization in the hippocampal formation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Cell</em>, 183(5):1249–1263, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib92">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Buesing et al. 2011<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lars Buesing, Johannes Bill, Bernhard Nessler, and Wolfgang Maass.

</span>
<span class="ltx_bibblock">Neural dynamics as sampling: a model for stochastic computation in recurrent networks of spiking neurons.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">PLoS computational biology</em>, 7(11):e1002211, 2011.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib93">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hihi and Bengio 1995<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Salah Hihi and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Hierarchical recurrent neural networks for long-term dependencies.

</span>
<span class="ltx_bibblock">In D. Touretzky, M.C. Mozer, and M. Hasselmo, editors, <em class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, volume 8. MIT Press, 1995.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib94">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koutník et al. 2014<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jan Koutník, Klaus Greff, Faustino J. Gomez, and Jürgen Schmidhuber.

</span>
<span class="ltx_bibblock">A clockwork rnn.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib95">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dehghani et al. 2018<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Mostafa Dehghani, Stephan Gouws, Oriol Vinyals, Jakob Uszkoreit, and Lukasz Kaiser.

</span>
<span class="ltx_bibblock">Universal transformers, 2018.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1807.03819.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib96">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. 2025<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yiping Wang, Qing Yang, Zhiyuan Zeng, Liliang Ren, Lucas Liu, Baolin Peng, Hao Cheng, Xuehai He, Kuan Wang, Jianfeng Gao, Weizhu Chen, Shuohang Wang, Simon Shaolei Du, and Yelong Shen.

</span>
<span class="ltx_bibblock">Reinforcement learning for reasoning in large language models with one training example, 2025.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2504.20571" title="">https://arxiv.org/abs/2504.20571</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib97">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Muennighoff 2025<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Niklas Muennighoff.

</span>
<span class="ltx_bibblock">s1: Simple test-time scaling.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2502.23456</em>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib98">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wen et al. 2025<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Liang Wen, Yunke Cai, Fenrui Xiao, Xin He, Qi An, Zhenyu Duan, Yimin Du, Junchen Liu, Lifu Tang, Xiaowei Lv, Haosheng Zou, Yongchao Deng, Shousheng Jia, and Xiangzheng Zhang.

</span>
<span class="ltx_bibblock">Light-r1: Curriculum sft, dpo and rl for long cot from scratch and beyond, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib99">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. 2025<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xuefeng Li, Haoyang Zou, and Pengfei Liu.

</span>
<span class="ltx_bibblock">Limr: Less is more for rl scaling, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib100">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dao and Gu 2024<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tri Dao and Albert Gu.

</span>
<span class="ltx_bibblock">Transformers are ssms: Generalized models and efficient algorithms through structured state space duality.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2405.21060, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib101">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al. 2025<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Han Guo, Songlin Yang, Tarushii Goel, Eric P Xing, Tri Dao, and Yoon Kim.

</span>
<span class="ltx_bibblock">Log-linear attention.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2506.04761</em>, 2025.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>

</div>


<button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue</button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed; display: none;">Report Issue for Selection</button><div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==">
            </a>
        </div></div><footer id="footer" class="ltx_document">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer></body></html>